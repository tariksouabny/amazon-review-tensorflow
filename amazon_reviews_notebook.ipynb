{
 "cells":[
  {
   "cell_type":"code",
   "source":[
    "import os, zipfile\n",
    "# Check if data is in zip format\n",
    "if os.path.exists(\"amazon_reviews_data.zip\"):\n",
    "    with zipfile.ZipFile(\"amazon_reviews_data.zip\") as zipref:\n",
    "        zipref.extractall()"
   ],
   "execution_count":1,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"MfxdtIWZPcpik4aPyxWjIz"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "!pip install -r --quiet requirements.txt"
   ],
   "execution_count":2,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: '--quiet'\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\r\n",
      "You should consider upgrading via the '\/opt\/python\/envs\/default\/bin\/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"XxSItztoflUYd9kWknCsYe"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Find any csv files and rename them\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "file_pattern = re.compile(\"\\.csv\")\n",
    "#iterate through files starting at cwd\n",
    "for root, dirs, files in os.walk(os.getcwd()):\n",
    "    # log current files\n",
    "    print(f\"FILES ARE: {files}\")\n",
    "    # search if filename contains \".csv\"\n",
    "    for file_ in files:\n",
    "        if file_pattern.findall(file_):\n",
    "            print(f\"CSV File Found:\\t {file_}\")\n",
    "            # rename found file to 'amazon_reviews.csv'\n",
    "            os.rename(file_, os.path.join(os.getcwd(), \"amazon_reviews.csv\"))"
   ],
   "execution_count":3,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "FILES ARE: ['7817_1.csv', 'requirements.txt', 'amazon_reviews.csv', 'amazon_reviews_data.zip', 'environment.yml']\n",
      "CSV File Found:\t 7817_1.csv\n",
      "CSV File Found:\t amazon_reviews.csv\n",
      "FILES ARE: []\n",
      "FILES ARE: []\n",
      "FILES ARE: []\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"iBtNvDFLUruFYGoPLRvEB5"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Import data\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "dataset_full = pd.read_csv(\"amazon_reviews.csv\")\n",
    "dataset_full.head(10)"
   ],
   "execution_count":4,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>id<\/th>\n",
       "      <th>asins<\/th>\n",
       "      <th>brand<\/th>\n",
       "      <th>categories<\/th>\n",
       "      <th>colors<\/th>\n",
       "      <th>dateAdded<\/th>\n",
       "      <th>dateUpdated<\/th>\n",
       "      <th>dimension<\/th>\n",
       "      <th>ean<\/th>\n",
       "      <th>keys<\/th>\n",
       "      <th>...<\/th>\n",
       "      <th>reviews.rating<\/th>\n",
       "      <th>reviews.sourceURLs<\/th>\n",
       "      <th>reviews.text<\/th>\n",
       "      <th>reviews.title<\/th>\n",
       "      <th>reviews.userCity<\/th>\n",
       "      <th>reviews.userProvince<\/th>\n",
       "      <th>reviews.username<\/th>\n",
       "      <th>sizes<\/th>\n",
       "      <th>upc<\/th>\n",
       "      <th>weight<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>5.0<\/td>\n",
       "      <td>https:\/\/www.amazon.com\/Kindle-Paperwhite-High-...<\/td>\n",
       "      <td>I initially had trouble deciding between the p...<\/td>\n",
       "      <td>Paperwhite voyage, no regrets!<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Cristina M<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>5.0<\/td>\n",
       "      <td>https:\/\/www.amazon.com\/Kindle-Paperwhite-High-...<\/td>\n",
       "      <td>Allow me to preface this with a little history...<\/td>\n",
       "      <td>One Simply Could Not Ask For More<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Ricky<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>4.0<\/td>\n",
       "      <td>https:\/\/www.amazon.com\/Kindle-Paperwhite-High-...<\/td>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...<\/td>\n",
       "      <td>Great for those that just want an e-reader<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Tedd Gardiner<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>3<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>5.0<\/td>\n",
       "      <td>https:\/\/www.amazon.com\/Kindle-Paperwhite-High-...<\/td>\n",
       "      <td>I bought one of the first Paperwhites and have...<\/td>\n",
       "      <td>Love \/ Hate relationship<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Dougal<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>4<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>5.0<\/td>\n",
       "      <td>https:\/\/www.amazon.com\/Kindle-Paperwhite-High-...<\/td>\n",
       "      <td>I have to say upfront - I don't like coroporat...<\/td>\n",
       "      <td>I LOVE IT<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Miljan David Tanic<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>5<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>http:\/\/www.amazon.com\/Kindle-Paperwhite-High-R...<\/td>\n",
       "      <td>My previous kindle was a DX, this is my second...<\/td>\n",
       "      <td>Great device for reading. 8 people found this ...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Kelvin Law<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>6<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>http:\/\/www.amazon.com\/Kindle-Paperwhite-High-R...<\/td>\n",
       "      <td>Allow me to preface this with a little history...<\/td>\n",
       "      <td>One Simply Could Not Ask For More 28 people fo...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Ricky<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>7<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>http:\/\/www.amazon.com\/Kindle-Paperwhite-High-R...<\/td>\n",
       "      <td>Just got mine right now. Looks the same as the...<\/td>\n",
       "      <td>Definitely better than the previous generation...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Bandler<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>8<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>http:\/\/www.amazon.com\/Kindle-Paperwhite-High-R...<\/td>\n",
       "      <td>I initially had trouble deciding between the p...<\/td>\n",
       "      <td>Paperwhite voyage, no regrets! 16 people found...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Cristina M<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>9<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>http:\/\/www.amazon.com\/Kindle-Paperwhite-High-R...<\/td>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...<\/td>\n",
       "      <td>Great for those that just want an e-reader 19 ...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Tedd Gardiner<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<p>10 rows × 27 columns<\/p>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"AOMFhcIgEb5UA8prb6UhlR"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Get the columns and length of the full dataset\n",
    "\n",
    "print(dataset_full.columns)\n",
    "print(len(dataset_full))"
   ],
   "execution_count":5,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Index(['id', 'asins', 'brand', 'categories', 'colors', 'dateAdded',\n",
      "       'dateUpdated', 'dimension', 'ean', 'keys', 'manufacturer',\n",
      "       'manufacturerNumber', 'name', 'prices', 'reviews.date',\n",
      "       'reviews.doRecommend', 'reviews.numHelpful', 'reviews.rating',\n",
      "       'reviews.sourceURLs', 'reviews.text', 'reviews.title',\n",
      "       'reviews.userCity', 'reviews.userProvince', 'reviews.username', 'sizes',\n",
      "       'upc', 'weight'],\n",
      "      dtype='object')\n",
      "1597\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"VSwB3aDUZNed6oljFBY36n"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Drop NaN values and create train_and_target_data\n",
    "\n",
    "# Will drop all columns exept for the review title and text\n",
    "train_and_target_data = dataset_full[[\"reviews.title\", \"reviews.text\", \"reviews.rating\"]]\n",
    "train_and_target_data = train_and_target_data.dropna()\n",
    "\n",
    "clean_data_train = train_and_target_data[[\"reviews.title\", \"reviews.text\"]]\n",
    "clean_data_train.head(10)"
   ],
   "execution_count":6,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>reviews.title<\/th>\n",
       "      <th>reviews.text<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>Paperwhite voyage, no regrets!<\/td>\n",
       "      <td>I initially had trouble deciding between the p...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>One Simply Could Not Ask For More<\/td>\n",
       "      <td>Allow me to preface this with a little history...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>Great for those that just want an e-reader<\/td>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>3<\/th>\n",
       "      <td>Love \/ Hate relationship<\/td>\n",
       "      <td>I bought one of the first Paperwhites and have...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>4<\/th>\n",
       "      <td>I LOVE IT<\/td>\n",
       "      <td>I have to say upfront - I don't like coroporat...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>13<\/th>\n",
       "      <td>Liked the smaller size<\/td>\n",
       "      <td>Had older model, that you could text to speech...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>14<\/th>\n",
       "      <td>Superb reading device - but which one's best f...<\/td>\n",
       "      <td>This is a review of the Kindle Paperwhite laun...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>15<\/th>\n",
       "      <td>I love it!<\/td>\n",
       "      <td>I love my kindle! I got one for my fiance on h...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>16<\/th>\n",
       "      <td>Un plaisir<\/td>\n",
       "      <td>Vraiment bon petit appareil , lger et facile d...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>17<\/th>\n",
       "      <td>Works great and I love the built-in light<\/td>\n",
       "      <td>Exactly what it is supposed to be. Works great...<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"5PsJ251dWxxSEgOUdhE5AT"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Create test data\n",
    "\n",
    "clean_data_test = train_and_target_data[\"reviews.rating\"]\n",
    "clean_data_test.head(10)"
   ],
   "execution_count":7,
   "outputs":[
    {
     "data":{
      "text\/html":[
       
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"YgnEzzylYvGw5VFdEfaQNi"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import plotly.express as px\n",
    "px.histogram(data_frame=clean_data_test)"
   ],
   "execution_count":8,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "Unsupported"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"0U7cjLBRwKI1048NXgWuqa"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "print(\n",
    "    f\"Ratio of Non-NaN vals in ratings to total vals: {len(clean_data_test.dropna())\/len(clean_data_test)}\"\n",
    ")"
   ],
   "execution_count":9,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Ratio of Non-NaN vals in ratings to total vals: 1.0\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"jwSfPv7zV4vibKXtF54CX6"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(clean_data_train.to_numpy(),\n",
    "                                                                            clean_data_test.to_numpy(),\n",
    "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
    "                                                                            random_state=42) # random state for reproducibility\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Currently, X_train and X_test are arrays with two features: The title of the review and the description\n",
    "# It would be appropriate to simply join the title with the description.\n",
    "\n",
    "\n",
    "\n",
    "# Input: np.ndarray -> Output: np.ndarray\n",
    "def join_titles_sentences(data_np):\n",
    "    new_data = np.array(list(\n",
    "    '. '.join(str(feature) for feature in review) for review in data_np\n",
    "))\n",
    "    return new_data\n",
    "\n",
    "x_train = join_titles_sentences(train_sentences)\n",
    "print(f\"INFO OF x_train:\\n\\t {np.info(x_train)}\\n\")\n",
    "print(f\"FIRST SAMPLE OF x_train:\\n\\t {x_train[0]}\\n\")\n",
    "print(f\"SHAPE OF FIRST SAMPLE:\\t\\n{x_train[0].shape}\")\n",
    "y_train = train_labels\n",
    "print(f\"INFO OF y_train:\\n\\t {np.info(y_train)}\\n\")\n",
    "print(f\"FIRST SAMPLE OF y_train:\\n\\t {y_train[0]}\\n\")\n",
    "print(f\"SHAPE OF FIRST SAMPLE:\\t\\n{y_train[0].shape}\")\n",
    "\n",
    "print(np.info(x_train), '\\n')\n",
    "print(x_train[0], '\\n')\n"
   ],
   "execution_count":10,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "class:  ndarray\n",
      "shape:  (1059,)\n",
      "strides:  (79408,)\n",
      "itemsize:  79408\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  True\n",
      "data pointer: 0x7fefbd37e010\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: <U19852\n",
      "INFO OF x_train:\n",
      "\t None\n",
      "\n",
      "FIRST SAMPLE OF x_train:\n",
      "\t Amazon Tap brings a new meaning to portable music. Amazon Echo is great. But it is stuck at home. Amazon Tap on the other hand goes everywhere. In the short time we have had ours, we have brought it to Sweden, Portugal, the lake up north and friend's houses. It has served as a music host at card games, answered questions and added things to our shopping list. It is easy to set up Amazon Tap to a wifi network using the Alexa app on your smartphone. You can also easily pair several devices to the Tap via Bluetooth. What really makes this device great is that the cloud based software is continually updated. New skills and capabilities are made available on a regular basis. Amazon really hit home with the Tap as the voice interface is so easy to use, and the portability makes it a great.\n",
      "\n",
      "SHAPE OF FIRST SAMPLE:\t\n",
      "()\n",
      "class:  ndarray\n",
      "shape:  (1059,)\n",
      "strides:  (8,)\n",
      "itemsize:  8\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  True\n",
      "data pointer: 0x560fec588d70\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: float64\n",
      "INFO OF y_train:\n",
      "\t None\n",
      "\n",
      "FIRST SAMPLE OF y_train:\n",
      "\t 5.0\n",
      "\n",
      "SHAPE OF FIRST SAMPLE:\t\n",
      "()\n",
      "class:  ndarray\n",
      "shape:  (1059,)\n",
      "strides:  (79408,)\n",
      "itemsize:  79408\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  True\n",
      "data pointer: 0x7fefbd37e010\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: <U19852\n",
      "None \n",
      "\n",
      "Amazon Tap brings a new meaning to portable music. Amazon Echo is great. But it is stuck at home. Amazon Tap on the other hand goes everywhere. In the short time we have had ours, we have brought it to Sweden, Portugal, the lake up north and friend's houses. It has served as a music host at card games, answered questions and added things to our shopping list. It is easy to set up Amazon Tap to a wifi network using the Alexa app on your smartphone. You can also easily pair several devices to the Tap via Bluetooth. What really makes this device great is that the cloud based software is continually updated. New skills and capabilities are made available on a regular basis. Amazon really hit home with the Tap as the voice interface is so easy to use, and the portability makes it a great. \n",
      "\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"b1CH5wlpv6Ktd6RqPISvtc"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Embedding\n",
    "\n",
    "MAX_TOKENS = 2**13\n",
    "MAX_SEQ_LENGTH = 20\n",
    "OOV_TOKEN = \"<OOV>\"\n",
    "\n",
    "def texts_to_seq(train_data, method=\"tokenizer\"):\n",
    "\n",
    "    '''\n",
    "\n",
    "    Returns the given text dataset into a sequence dataset.\n",
    "\n",
    "    Parameters: \n",
    "        train_data - the training text to train on\n",
    "        method: ∈ {\"tokenizer\"} - the method by which to convert to sequence\n",
    "    '''\n",
    "\n",
    "    if method==\"tokenizer\":\n",
    "        from keras.preprocessing.text import Tokenizer\n",
    "        from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "        tokenizer_one = Tokenizer(\n",
    "        num_words=MAX_TOKENS,\n",
    "        oov_token=OOV_TOKEN\n",
    "        )\n",
    "\n",
    "        tokenizer_one.fit_on_texts(train_data)\n",
    "\n",
    "        without_padding_data = tokenizer_one.texts_to_sequences(train_data)\n",
    "        return pad_sequences(without_padding_data, 200)"
   ],
   "execution_count":11,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"04F4nYJrQD6XsciZ42CH4x"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Make a naive bayes baseline classifier;\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "naive_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"classifier\", MultinomialNB())\n",
    "])\n",
    "\n",
    "model_0 = naive_pipeline.fit(x_train, train_labels)\n",
    "baseline_score = model_0.score(x_train, y_train)\n",
    "baseline_score"
   ],
   "execution_count":12,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "0.6685552407932012"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"yl6cT44GvEvFnqLwtYMTDD"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# make a function to evaluate with fscores, precision, recall\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import math\n",
    "\n",
    "# np.ndarray -> np.ndarray\n",
    "def score_fscore_precision_recall(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\n",
    "        \"accuracy\":accuracy,\n",
    "        \"model precision\":model_precision,\n",
    "        \"model recall\": model_recall,\n",
    "        \"model F1 score\": model_f1,\n",
    "        \"mean score\": np.mean([accuracy, model_precision, model_recall, model_f1])\n",
    "    }\n",
    "    return model_results"
   ],
   "execution_count":13,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"Qxbxc52Ic7WiC898j0P6fQ"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "score_fscore_precision_recall(model_0.predict(x_train), y_train)"
   ],
   "execution_count":14,
   "outputs":[
    {
     "name":"stderr",
     "text":[
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/metrics\/_classification.py:1308: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      "text\/plain":[
       "{'accuracy': 0.6685552407932012,\n",
       " 'model precision': 0.9763162958885474,\n",
       " 'model recall': 0.6685552407932012,\n",
       " 'model F1 score': 0.7813679711816148,\n",
       " 'mean score': 0.7736986871641411}"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"ycxr1F3ZuzAtvIjFFJ94I6"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Make a model one (dense model)\n",
    "\n",
    "## Important layers    \n",
    "\n",
    "embedding_layer_one = Embedding(\n",
    "    input_dim=MAX_TOKENS,\n",
    "    output_dim=128,\n",
    "    input_length=200,\n",
    "    name=\"embedding_one\"\n",
    ")"
   ],
   "execution_count":15,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"EWFcL6WX4V9E4fj7QopK3E"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Model 1 - Dense Model\n",
    "'''x = texts_to_seq(inputs)\n",
    "x = embedding_layer_one(x)\n",
    "x = keras.layers.GlobalAveragePooling1D()(x)\n",
    "outputs = keras.layers.Dense(5, activation=\"softmax\")(x)\n",
    "model_1 = keras.models.Model(inputs=inputs, outputs=outputs, name=\"model_1\")\n",
    "\n",
    "'''\n",
    "\n",
    "model_1 = keras.models.Sequential([\n",
    "    embedding_layer_one,\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(12)),\n",
    "    keras.layers.Dense(6, activation=\"softmax\")\n",
    "])"
   ],
   "execution_count":16,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"ockGxLK2lXXXcEDK8qbaHy"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def preprocess_seq(train_x, test_x):\n",
    "\n",
    "    return tf.cast(texts_to_seq(train_x), tf.int32), test_x\n",
    "\n",
    "preprocessed_x_train, preprocessed_y_train = preprocess_seq(x_train, y_train)\n",
    "print(preprocessed_x_train[0])\n",
    "print(preprocessed_y_train[0])\n",
    "np.info(np.array(preprocessed_x_train))"
   ],
   "execution_count":17,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "tf.Tensor(\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0   25   65 2967    6\n",
      "   72 1602    3  223  100   25   59    8   23   17    7    8 1692   36\n",
      "  221   25   65   18    2  105  830  966 2186   15    2  450   95  119\n",
      "   19   76 3757  119   19 1174    7    3 3758 3759    2 2968   71 3760\n",
      "    5 3761 2969    7   53 2515   20    6  100 2970   36  831  367 1693\n",
      "  427    5  342  138    3  265 1031  571    7    8  107    3  167   71\n",
      "   25   65    3    6  308 1235  115    2   91  172   18   43  491   12\n",
      "   34   85  362  439  399  227    3    2   65  508  222   89   87  428\n",
      "   11   63   23    8   13    2  538  752  382    8 2516  378   72 1694\n",
      "    5 1000   22  293  243   18    6  345 1309   25   87  967  221   16\n",
      "    2   65   20    2  163  480    8   26  107    3   40    5    2  492\n",
      "  428    7    6   23], shape=(200,), dtype=int32)\n",
      "5.0\n",
      "class:  ndarray\n",
      "shape:  (1059, 200)\n",
      "strides:  (800, 4)\n",
      "itemsize:  4\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  False\n",
      "data pointer: 0x560ff09d6080\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: int32\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"DcD0cYomDMFPIp8W0Noufq"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "val_sent, val_lab = preprocess_seq(join_titles_sentences(val_sentences), val_labels)"
   ],
   "execution_count":18,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"4EhMyxVTI4N79uoJclSYeG"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "model_1.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, nesterov=True, momentum=0.99), metrics=['accuracy'])"
   ],
   "execution_count":19,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"ydueK51jafLtUmdDvpXGWQ"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "\n",
    "val_sent, val_lab = preprocess_seq(join_titles_sentences(val_sentences), val_labels)\n",
    "history = model_1.fit(preprocessed_x_train, y_train, epochs=5, validation_data=(val_sent, val_lab))"
   ],
   "execution_count":20,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Epoch 1\/5\n",
      "\r 1\/34 [..............................] - ETA: 4:32 - loss: 1.7928 - accuracy: 0.0625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2\/34 [>.............................] - ETA: 13s - loss: 1.7798 - accuracy: 0.3281 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3\/34 [=>............................] - ETA: 12s - loss: 1.7610 - accuracy: 0.4271\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4\/34 [==>...........................] - ETA: 12s - loss: 1.7401 - accuracy: 0.4688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5\/34 [===>..........................] - ETA: 12s - loss: 1.7172 - accuracy: 0.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6\/34 [====>.........................] - ETA: 12s - loss: 1.6921 - accuracy: 0.5156\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7\/34 [=====>........................] - ETA: 11s - loss: 1.6555 - accuracy: 0.5402\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8\/34 [======>.......................] - ETA: 11s - loss: 1.6186 - accuracy: 0.5586\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9\/34 [======>.......................] - ETA: 10s - loss: 1.5937 - accuracy: 0.5556\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10\/34 [=======>......................] - ETA: 10s - loss: 1.5628 - accuracy: 0.5656\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11\/34 [========>.....................] - ETA: 9s - loss: 1.5240 - accuracy: 0.5795 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12\/34 [=========>....................] - ETA: 9s - loss: 1.4898 - accuracy: 0.5885\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13\/34 [==========>...................] - ETA: 9s - loss: 1.4697 - accuracy: 0.5889\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14\/34 [===========>..................] - ETA: 8s - loss: 1.4771 - accuracy: 0.5737\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15\/34 [============>.................] - ETA: 8s - loss: 1.4410 - accuracy: 0.5854\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16\/34 [=============>................] - ETA: 7s - loss: 1.4186 - accuracy: 0.5898\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17\/34 [==============>...............] - ETA: 7s - loss: 1.4117 - accuracy: 0.5882\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18\/34 [==============>...............] - ETA: 6s - loss: 1.3913 - accuracy: 0.5920\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19\/34 [===============>..............] - ETA: 6s - loss: 1.3605 - accuracy: 0.6003\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20\/34 [================>.............] - ETA: 5s - loss: 1.3422 - accuracy: 0.6062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21\/34 [=================>............] - ETA: 5s - loss: 1.3355 - accuracy: 0.6071\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22\/34 [==================>...........] - ETA: 5s - loss: 1.3337 - accuracy: 0.6065\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23\/34 [===================>..........] - ETA: 4s - loss: 1.3180 - accuracy: 0.6087\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24\/34 [====================>.........] - ETA: 4s - loss: 1.3099 - accuracy: 0.6107\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25\/34 [=====================>........] - ETA: 3s - loss: 1.3016 - accuracy: 0.6125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r26\/34 [=====================>........] - ETA: 3s - loss: 1.2905 - accuracy: 0.6190\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27\/34 [======================>.......] - ETA: 2s - loss: 1.2746 - accuracy: 0.6227\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/34 [=======================>......] - ETA: 2s - loss: 1.2824 - accuracy: 0.6183\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29\/34 [========================>.....] - ETA: 2s - loss: 1.2718 - accuracy: 0.6218\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30\/34 [=========================>....] - ETA: 1s - loss: 1.2708 - accuracy: 0.6198\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31\/34 [==========================>...] - ETA: 1s - loss: 1.2667 - accuracy: 0.6169\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32\/34 [===========================>..] - ETA: 0s - loss: 1.2556 - accuracy: 0.6191\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33\/34 [============================>.] - ETA: 0s - loss: 1.2520 - accuracy: 0.6212\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34\/34 [==============================] - ETA: 0s - loss: 1.2506 - accuracy: 0.6213\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34\/34 [==============================] - 24s 488ms\/step - loss: 1.2506 - accuracy: 0.6213 - val_loss: 1.2731 - val_accuracy: 0.5763\n",
      "Epoch 2\/5\n",
      "\r 1\/34 [..............................] - ETA: 13s - loss: 1.2902 - accuracy: 0.5312\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2\/34 [>.............................] - ETA: 13s - loss: 1.2788 - accuracy: 0.5469\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3\/34 [=>............................] - ETA: 13s - loss: 1.1131 - accuracy: 0.6042\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4\/34 [==>...........................] - ETA: 12s - loss: 1.0957 - accuracy: 0.6250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5\/34 [===>..........................] - ETA: 12s - loss: 1.1442 - accuracy: 0.6250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6\/34 [====>.........................] - ETA: 12s - loss: 1.1069 - accuracy: 0.6458\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7\/34 [=====>........................] - ETA: 11s - loss: 1.0455 - accuracy: 0.6652\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8\/34 [======>.......................] - ETA: 11s - loss: 1.0941 - accuracy: 0.6484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9\/34 [======>.......................] - ETA: 10s - loss: 1.1118 - accuracy: 0.6458\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10\/34 [=======>......................] - ETA: 10s - loss: 1.0917 - accuracy: 0.6500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11\/34 [========>.....................] - ETA: 10s - loss: 1.0780 - accuracy: 0.6449\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12\/34 [=========>....................] - ETA: 9s - loss: 1.0978 - accuracy: 0.6328 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13\/34 [==========>...................] - ETA: 9s - loss: 1.0937 - accuracy: 0.6370\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14\/34 [===========>..................] - ETA: 8s - loss: 1.0931 - accuracy: 0.6362\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15\/34 [============>.................] - ETA: 8s - loss: 1.0948 - accuracy: 0.6375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16\/34 [=============>................] - ETA: 7s - loss: 1.0802 - accuracy: 0.6484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17\/34 [==============>...............] - ETA: 7s - loss: 1.0947 - accuracy: 0.6434\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18\/34 [==============>...............] - ETA: 7s - loss: 1.0964 - accuracy: 0.6458\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19\/34 [===============>..............] - ETA: 6s - loss: 1.1002 - accuracy: 0.6398\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20\/34 [================>.............] - ETA: 6s - loss: 1.0880 - accuracy: 0.6438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21\/34 [=================>............] - ETA: 5s - loss: 1.0746 - accuracy: 0.6473\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22\/34 [==================>...........] - ETA: 5s - loss: 1.0837 - accuracy: 0.6406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23\/34 [===================>..........] - ETA: 4s - loss: 1.0876 - accuracy: 0.6386\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24\/34 [====================>.........] - ETA: 4s - loss: 1.0886 - accuracy: 0.6380\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25\/34 [=====================>........] - ETA: 3s - loss: 1.0840 - accuracy: 0.6363\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r26\/34 [=====================>........] - ETA: 3s - loss: 1.0846 - accuracy: 0.6358\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27\/34 [======================>.......] - ETA: 3s - loss: 1.0801 - accuracy: 0.6377\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/34 [=======================>......] - ETA: 2s - loss: 1.0777 - accuracy: 0.6395\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29\/34 [========================>.....] - ETA: 2s - loss: 1.0838 - accuracy: 0.6390\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30\/34 [=========================>....] - ETA: 1s - loss: 1.0869 - accuracy: 0.6385\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31\/34 [==========================>...] - ETA: 1s - loss: 1.0892 - accuracy: 0.6371\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32\/34 [===========================>..] - ETA: 0s - loss: 1.0885 - accuracy: 0.6377\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33\/34 [============================>.] - ETA: 0s - loss: 1.0925 - accuracy: 0.6354\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34\/34 [==============================] - ETA: 0s - loss: 1.0920 - accuracy: 0.6355\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34\/34 [==============================] - 15s 432ms\/step - loss: 1.0920 - accuracy: 0.6355 - val_loss: 1.2662 - val_accuracy: 0.5763\n",
      "Epoch 3\/5\n",
      "\r 1\/34 [..............................] - ETA: 12s - loss: 0.9281 - accuracy: 0.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2\/34 [>.............................] - ETA: 14s - loss: 0.8834 - accuracy: 0.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3\/34 [=>............................] - ETA: 13s - loss: 1.0515 - accuracy: 0.6979\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4\/34 [==>...........................] - ETA: 13s - loss: 1.0281 - accuracy: 0.6797\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5\/34 [===>..........................] - ETA: 12s - loss: 1.0097 - accuracy: 0.7000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6\/34 [====>.........................] - ETA: 12s - loss: 1.0337 - accuracy: 0.6823\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7\/34 [=====>........................] - ETA: 11s - loss: 1.0305 - accuracy: 0.6830\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8\/34 [======>.......................] - ETA: 11s - loss: 1.0795 - accuracy: 0.6562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9\/34 [======>.......................] - ETA: 10s - loss: 1.0717 - accuracy: 0.6493\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10\/34 [=======>......................] - ETA: 10s - loss: 1.0848 - accuracy: 0.6406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11\/34 [========>.....................] - ETA: 9s - loss: 1.0862 - accuracy: 0.6392 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12\/34 [=========>....................] - ETA: 9s - loss: 1.1034 - accuracy: 0.6302\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13\/34 [==========>...................] - ETA: 9s - loss: 1.0850 - accuracy: 0.6394\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14\/34 [===========>..................] - ETA: 8s - loss: 1.0869 - accuracy: 0.6406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15\/34 [============>.................] - ETA: 8s - loss: 1.0947 - accuracy: 0.6396\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16\/34 [=============>................] - ETA: 7s - loss: 1.0813 - accuracy: 0.6426\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17\/34 [==============>...............] - ETA: 7s - loss: 1.0752 - accuracy: 0.6452\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18\/34 [==============>...............] - ETA: 6s - loss: 1.0563 - accuracy: 0.6528\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19\/34 [===============>..............] - ETA: 6s - loss: 1.0580 - accuracy: 0.6480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20\/34 [================>.............] - ETA: 5s - loss: 1.0520 - accuracy: 0.6469\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21\/34 [=================>............] - ETA: 5s - loss: 1.0635 - accuracy: 0.6384\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22\/34 [==================>...........] - ETA: 5s - loss: 1.0664 - accuracy: 0.6364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23\/34 [===================>..........] - ETA: 4s - loss: 1.0705 - accuracy: 0.6345\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24\/34 [====================>.........] - ETA: 4s - loss: 1.0620 - accuracy: 0.6367\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25\/34 [=====================>........] - ETA: 3s - loss: 1.0607 - accuracy: 0.6388\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r26\/34 [=====================>........] - ETA: 3s - loss: 1.0503 - accuracy: 0.6442\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27\/34 [======================>.......] - ETA: 2s - loss: 1.0535 - accuracy: 0.6424\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/34 [=======================>......] - ETA: 2s - loss: 1.0551 - accuracy: 0.6406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29\/34 [========================>.....] - ETA: 1s - loss: 1.0563 - accuracy: 0.6401\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30\/34 [=========================>....] - ETA: 1s - loss: 1.0602 - accuracy: 0.6385\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31\/34 [==========================>...] - ETA: 1s - loss: 1.0680 - accuracy: 0.6341\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32\/34 [===========================>..] - ETA: 0s - loss: 1.0639 - accuracy: 0.6348\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33\/34 [============================>.] - ETA: 0s - loss: 1.0670 - accuracy: 0.6345\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34\/34 [==============================] - ETA: 0s - loss: 1.0654 - accuracy: 0.6355\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34\/34 [==============================] - 13s 385ms\/step - loss: 1.0654 - accuracy: 0.6355 - val_loss: 1.2081 - val_accuracy: 0.5763\n",
      "Epoch 4\/5\n",
      "\r 1\/34 [..............................] - ETA: 10s - loss: 1.0171 - accuracy: 0.7188"
     ],
     "output_type":"stream"
    },
    {
     "ename":"KeyboardInterrupt",
     "evalue":"KeyboardInterrupt: ",
     "traceback":[
      "\u001b[0;31m---------------------------------------------------------------------------",
      "Traceback (most recent call last)",
      "    at line 2 in <module>",
      "    at line 64 in error_handler(*args, **kwargs)",
      "    at line 1384 in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)",
      "    at line 150 in error_handler(*args, **kwargs)",
      "    at line 915 in __call__(self, *args, **kwds)",
      "    at line 947 in _call(self, *args, **kwds)",
      "    at line 2956 in __call__(self, *args, **kwargs)",
      "    at line 1853 in _call_flat(self, args, captured_inputs, cancellation_manager)",
      "    at line 499 in call(self, ctx, args, cancellation_manager)",
      "    at line 54 in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)",
      "KeyboardInterrupt: "
     ],
     "output_type":"error"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"CAGhCvBcfr02nIZYrOqoHK"
    }
   }
  }
 ],
 "metadata":{
  "datalore":{
   "version":1,
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    {
     "name":"nltk",
     "version":"3.7",
     "source":"PIP"
    },
    {
     "name":"tensorflow-hub",
     "version":"0.12.0",
     "source":"PIP"
    },
    {
     "name":"tensorflow-text",
     "version":"2.8.1",
     "source":"PIP"
    }
   ]
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}