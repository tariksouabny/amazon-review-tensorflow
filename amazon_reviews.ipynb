{
 "cells":[
  {
   "cell_type":"code",
   "source":[
    "import os, zipfile\n",
    "# Check if data is in zip format\n",
    "if os.path.exists(\"amazon_reviews_data.zip\"):\n",
    "    with zipfile.ZipFile(\"amazon_reviews_data.zip\") as zipref:\n",
    "        zipref.extractall()"
   ],
   "execution_count":4,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"MfxdtIWZPcpik4aPyxWjIz"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Find any csv files and rename them\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "file_pattern = re.compile(\"\\.csv\")\n",
    "#iterate through files starting at cwd\n",
    "for root, dirs, files in os.walk(os.getcwd()):\n",
    "    # log current files\n",
    "    print(f\"FILES ARE: {files}\")\n",
    "    # search if filename contains \".csv\"\n",
    "    for file_ in files:\n",
    "        if file_pattern.findall(file_):\n",
    "            print(f\"CSV File Found:\\t {file_}\")\n",
    "            # rename found file to 'amazon_reviews.csv'\n",
    "            os.rename(file_, os.path.join(os.getcwd(), \"amazon_reviews.csv\"))"
   ],
   "execution_count":5,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "FILES ARE: ['7817_1.csv', 'amazon_reviews.csv', 'amazon_reviews_data.zip', 'environment.yml']\n",
      "CSV File Found:\t 7817_1.csv\n",
      "CSV File Found:\t amazon_reviews.csv\n",
      "FILES ARE: []\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"iBtNvDFLUruFYGoPLRvEB5"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Import data\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "dataset_full = pd.read_csv(\"amazon_reviews.csv\")\n",
    "dataset_full.head(10)"
   ],
   "execution_count":6,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>id<\/th>\n",
       "      <th>asins<\/th>\n",
       "      <th>brand<\/th>\n",
       "      <th>categories<\/th>\n",
       "      <th>colors<\/th>\n",
       "      <th>dateAdded<\/th>\n",
       "      <th>dateUpdated<\/th>\n",
       "      <th>dimension<\/th>\n",
       "      <th>ean<\/th>\n",
       "      <th>keys<\/th>\n",
       "      <th>...<\/th>\n",
       "      <th>reviews.rating<\/th>\n",
       "      <th>reviews.sourceURLs<\/th>\n",
       "      <th>reviews.text<\/th>\n",
       "      <th>reviews.title<\/th>\n",
       "      <th>reviews.userCity<\/th>\n",
       "      <th>reviews.userProvince<\/th>\n",
       "      <th>reviews.username<\/th>\n",
       "      <th>sizes<\/th>\n",
       "      <th>upc<\/th>\n",
       "      <th>weight<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>5.0<\/td>\n",
       "      <td>https:\/\/www.amazon.com\/Kindle-Paperwhite-High-...<\/td>\n",
       "      <td>I initially had trouble deciding between the p...<\/td>\n",
       "      <td>Paperwhite voyage, no regrets!<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Cristina M<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>5.0<\/td>\n",
       "      <td>https:\/\/www.amazon.com\/Kindle-Paperwhite-High-...<\/td>\n",
       "      <td>Allow me to preface this with a little history...<\/td>\n",
       "      <td>One Simply Could Not Ask For More<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Ricky<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>4.0<\/td>\n",
       "      <td>https:\/\/www.amazon.com\/Kindle-Paperwhite-High-...<\/td>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...<\/td>\n",
       "      <td>Great for those that just want an e-reader<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Tedd Gardiner<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>3<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>5.0<\/td>\n",
       "      <td>https:\/\/www.amazon.com\/Kindle-Paperwhite-High-...<\/td>\n",
       "      <td>I bought one of the first Paperwhites and have...<\/td>\n",
       "      <td>Love \/ Hate relationship<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Dougal<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>4<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>5.0<\/td>\n",
       "      <td>https:\/\/www.amazon.com\/Kindle-Paperwhite-High-...<\/td>\n",
       "      <td>I have to say upfront - I don't like coroporat...<\/td>\n",
       "      <td>I LOVE IT<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Miljan David Tanic<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>5<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>http:\/\/www.amazon.com\/Kindle-Paperwhite-High-R...<\/td>\n",
       "      <td>My previous kindle was a DX, this is my second...<\/td>\n",
       "      <td>Great device for reading. 8 people found this ...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Kelvin Law<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>6<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>http:\/\/www.amazon.com\/Kindle-Paperwhite-High-R...<\/td>\n",
       "      <td>Allow me to preface this with a little history...<\/td>\n",
       "      <td>One Simply Could Not Ask For More 28 people fo...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Ricky<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>7<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>http:\/\/www.amazon.com\/Kindle-Paperwhite-High-R...<\/td>\n",
       "      <td>Just got mine right now. Looks the same as the...<\/td>\n",
       "      <td>Definitely better than the previous generation...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Bandler<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>8<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>http:\/\/www.amazon.com\/Kindle-Paperwhite-High-R...<\/td>\n",
       "      <td>I initially had trouble deciding between the p...<\/td>\n",
       "      <td>Paperwhite voyage, no regrets! 16 people found...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Cristina M<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>9<\/th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G<\/td>\n",
       "      <td>B00QJDU3KY<\/td>\n",
       "      <td>Amazon<\/td>\n",
       "      <td>Amazon Devices,mazon.co.uk<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>2016-03-08T20:21:53Z<\/td>\n",
       "      <td>2017-07-18T23:52:58Z<\/td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>kindlepaperwhite\/b00qjdu3ky<\/td>\n",
       "      <td>...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>http:\/\/www.amazon.com\/Kindle-Paperwhite-High-R...<\/td>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...<\/td>\n",
       "      <td>Great for those that just want an e-reader 19 ...<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>Tedd Gardiner<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>NaN<\/td>\n",
       "      <td>205 grams<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<p>10 rows × 27 columns<\/p>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"AOMFhcIgEb5UA8prb6UhlR"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Get the columns and length of the full dataset\n",
    "\n",
    "print(dataset_full.columns)\n",
    "print(len(dataset_full))"
   ],
   "execution_count":7,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Index(['id', 'asins', 'brand', 'categories', 'colors', 'dateAdded',\n",
      "       'dateUpdated', 'dimension', 'ean', 'keys', 'manufacturer',\n",
      "       'manufacturerNumber', 'name', 'prices', 'reviews.date',\n",
      "       'reviews.doRecommend', 'reviews.numHelpful', 'reviews.rating',\n",
      "       'reviews.sourceURLs', 'reviews.text', 'reviews.title',\n",
      "       'reviews.userCity', 'reviews.userProvince', 'reviews.username', 'sizes',\n",
      "       'upc', 'weight'],\n",
      "      dtype='object')\n",
      "1597\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"VSwB3aDUZNed6oljFBY36n"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Print information about the columns\n",
    "\n",
    "for column in dataset_full.columns:\n",
    "    print(\n",
    "    f\"{column.__str__()}:\\t{dataset_full[str(column)].value_counts}\\n\\n\"\n",
    "    )"
   ],
   "execution_count":8,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "id:\t<bound method IndexOpsMixin.value_counts of 0       AVpe7AsMilAPnD_xQ78G\n",
      "1       AVpe7AsMilAPnD_xQ78G\n",
      "2       AVpe7AsMilAPnD_xQ78G\n",
      "3       AVpe7AsMilAPnD_xQ78G\n",
      "4       AVpe7AsMilAPnD_xQ78G\n",
      "                ...         \n",
      "1592    AVpfo9ukilAPnD_xfhuj\n",
      "1593    AVpfo9ukilAPnD_xfhuj\n",
      "1594    AVpfo9ukilAPnD_xfhuj\n",
      "1595    AVpfo9ukilAPnD_xfhuj\n",
      "1596    AVpfo9ukilAPnD_xfhuj\n",
      "Name: id, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "asins:\t<bound method IndexOpsMixin.value_counts of 0       B00QJDU3KY\n",
      "1       B00QJDU3KY\n",
      "2       B00QJDU3KY\n",
      "3       B00QJDU3KY\n",
      "4       B00QJDU3KY\n",
      "           ...    \n",
      "1592    B00NO8JJZW\n",
      "1593    B00NO8JJZW\n",
      "1594    B00NO8JJZW\n",
      "1595    B00NO8JJZW\n",
      "1596    B00NO8JJZW\n",
      "Name: asins, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "brand:\t<bound method IndexOpsMixin.value_counts of 0       Amazon\n",
      "1       Amazon\n",
      "2       Amazon\n",
      "3       Amazon\n",
      "4       Amazon\n",
      "         ...  \n",
      "1592    Amazon\n",
      "1593    Amazon\n",
      "1594    Amazon\n",
      "1595    Amazon\n",
      "1596    Amazon\n",
      "Name: brand, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "categories:\t<bound method IndexOpsMixin.value_counts of 0                              Amazon Devices,mazon.co.uk\n",
      "1                              Amazon Devices,mazon.co.uk\n",
      "2                              Amazon Devices,mazon.co.uk\n",
      "3                              Amazon Devices,mazon.co.uk\n",
      "4                              Amazon Devices,mazon.co.uk\n",
      "                              ...                        \n",
      "1592    Amazon Devices & Accessories,Amazon Device Acc...\n",
      "1593    Amazon Devices & Accessories,Amazon Device Acc...\n",
      "1594    Amazon Devices & Accessories,Amazon Device Acc...\n",
      "1595    Amazon Devices & Accessories,Amazon Device Acc...\n",
      "1596    Amazon Devices & Accessories,Amazon Device Acc...\n",
      "Name: categories, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "colors:\t<bound method IndexOpsMixin.value_counts of 0       NaN\n",
      "1       NaN\n",
      "2       NaN\n",
      "3       NaN\n",
      "4       NaN\n",
      "       ... \n",
      "1592    NaN\n",
      "1593    NaN\n",
      "1594    NaN\n",
      "1595    NaN\n",
      "1596    NaN\n",
      "Name: colors, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "dateAdded:\t<bound method IndexOpsMixin.value_counts of 0       2016-03-08T20:21:53Z\n",
      "1       2016-03-08T20:21:53Z\n",
      "2       2016-03-08T20:21:53Z\n",
      "3       2016-03-08T20:21:53Z\n",
      "4       2016-03-08T20:21:53Z\n",
      "                ...         \n",
      "1592    2016-04-02T14:40:43Z\n",
      "1593    2016-04-02T14:40:43Z\n",
      "1594    2016-04-02T14:40:43Z\n",
      "1595    2016-04-02T14:40:43Z\n",
      "1596    2016-04-02T14:40:43Z\n",
      "Name: dateAdded, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "dateUpdated:\t<bound method IndexOpsMixin.value_counts of 0       2017-07-18T23:52:58Z\n",
      "1       2017-07-18T23:52:58Z\n",
      "2       2017-07-18T23:52:58Z\n",
      "3       2017-07-18T23:52:58Z\n",
      "4       2017-07-18T23:52:58Z\n",
      "                ...         \n",
      "1592    2017-08-13T08:28:46Z\n",
      "1593    2017-08-13T08:28:46Z\n",
      "1594    2017-08-13T08:28:46Z\n",
      "1595    2017-08-13T08:28:46Z\n",
      "1596    2017-08-13T08:28:46Z\n",
      "Name: dateUpdated, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "dimension:\t<bound method IndexOpsMixin.value_counts of 0       169 mm x 117 mm x 9.1 mm\n",
      "1       169 mm x 117 mm x 9.1 mm\n",
      "2       169 mm x 117 mm x 9.1 mm\n",
      "3       169 mm x 117 mm x 9.1 mm\n",
      "4       169 mm x 117 mm x 9.1 mm\n",
      "                  ...           \n",
      "1592                         NaN\n",
      "1593                         NaN\n",
      "1594                         NaN\n",
      "1595                         NaN\n",
      "1596                         NaN\n",
      "Name: dimension, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "ean:\t<bound method IndexOpsMixin.value_counts of 0      NaN\n",
      "1      NaN\n",
      "2      NaN\n",
      "3      NaN\n",
      "4      NaN\n",
      "        ..\n",
      "1592   NaN\n",
      "1593   NaN\n",
      "1594   NaN\n",
      "1595   NaN\n",
      "1596   NaN\n",
      "Name: ean, Length: 1597, dtype: float64>\n",
      "\n",
      "\n",
      "keys:\t<bound method IndexOpsMixin.value_counts of 0                             kindlepaperwhite\/b00qjdu3ky\n",
      "1                             kindlepaperwhite\/b00qjdu3ky\n",
      "2                             kindlepaperwhite\/b00qjdu3ky\n",
      "3                             kindlepaperwhite\/b00qjdu3ky\n",
      "4                             kindlepaperwhite\/b00qjdu3ky\n",
      "                              ...                        \n",
      "1592    alexavoiceremoteforamazonfiretvfiretvstick\/b00...\n",
      "1593    alexavoiceremoteforamazonfiretvfiretvstick\/b00...\n",
      "1594    alexavoiceremoteforamazonfiretvfiretvstick\/b00...\n",
      "1595    alexavoiceremoteforamazonfiretvfiretvstick\/b00...\n",
      "1596    alexavoiceremoteforamazonfiretvfiretvstick\/b00...\n",
      "Name: keys, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "manufacturer:\t<bound method IndexOpsMixin.value_counts of 0       Amazon\n",
      "1       Amazon\n",
      "2       Amazon\n",
      "3       Amazon\n",
      "4       Amazon\n",
      "         ...  \n",
      "1592       NaN\n",
      "1593       NaN\n",
      "1594       NaN\n",
      "1595       NaN\n",
      "1596       NaN\n",
      "Name: manufacturer, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "manufacturerNumber:\t<bound method IndexOpsMixin.value_counts of 0          NaN\n",
      "1          NaN\n",
      "2          NaN\n",
      "3          NaN\n",
      "4          NaN\n",
      "         ...  \n",
      "1592    DR49WK\n",
      "1593    DR49WK\n",
      "1594    DR49WK\n",
      "1595    DR49WK\n",
      "1596    DR49WK\n",
      "Name: manufacturerNumber, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "name:\t<bound method IndexOpsMixin.value_counts of 0                                       Kindle Paperwhite\n",
      "1                                       Kindle Paperwhite\n",
      "2                                       Kindle Paperwhite\n",
      "3                                       Kindle Paperwhite\n",
      "4                                       Kindle Paperwhite\n",
      "                              ...                        \n",
      "1592    Alexa Voice Remote for Amazon Fire TV and Fire...\n",
      "1593    Alexa Voice Remote for Amazon Fire TV and Fire...\n",
      "1594    Alexa Voice Remote for Amazon Fire TV and Fire...\n",
      "1595    Alexa Voice Remote for Amazon Fire TV and Fire...\n",
      "1596    Alexa Voice Remote for Amazon Fire TV and Fire...\n",
      "Name: name, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "prices:\t<bound method IndexOpsMixin.value_counts of 0       [{\"amountMax\":139.99,\"amountMin\":139.99,\"curre...\n",
      "1       [{\"amountMax\":139.99,\"amountMin\":139.99,\"curre...\n",
      "2       [{\"amountMax\":139.99,\"amountMin\":139.99,\"curre...\n",
      "3       [{\"amountMax\":139.99,\"amountMin\":139.99,\"curre...\n",
      "4       [{\"amountMax\":139.99,\"amountMin\":139.99,\"curre...\n",
      "                              ...                        \n",
      "1592    [{\"amountMax\":29.99,\"amountMin\":29.99,\"currenc...\n",
      "1593    [{\"amountMax\":29.99,\"amountMin\":29.99,\"currenc...\n",
      "1594    [{\"amountMax\":29.99,\"amountMin\":29.99,\"currenc...\n",
      "1595    [{\"amountMax\":29.99,\"amountMin\":29.99,\"currenc...\n",
      "1596    [{\"amountMax\":29.99,\"amountMin\":29.99,\"currenc...\n",
      "Name: prices, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "reviews.date:\t<bound method IndexOpsMixin.value_counts of 0       2015-08-08T00:00:00.000Z\n",
      "1       2015-09-01T00:00:00.000Z\n",
      "2       2015-07-20T00:00:00.000Z\n",
      "3       2017-06-16T00:00:00.000Z\n",
      "4       2016-08-11T00:00:00.000Z\n",
      "                  ...           \n",
      "1592    2016-07-06T00:00:00.000Z\n",
      "1593    2016-06-22T00:00:00.000Z\n",
      "1594    2016-03-31T00:00:00.000Z\n",
      "1595        2016-04-26T00:00:00Z\n",
      "1596        2016-07-31T00:00:00Z\n",
      "Name: reviews.date, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "reviews.doRecommend:\t<bound method IndexOpsMixin.value_counts of 0       NaN\n",
      "1       NaN\n",
      "2       NaN\n",
      "3       NaN\n",
      "4       NaN\n",
      "       ... \n",
      "1592    NaN\n",
      "1593    NaN\n",
      "1594    NaN\n",
      "1595    NaN\n",
      "1596    NaN\n",
      "Name: reviews.doRecommend, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "reviews.numHelpful:\t<bound method IndexOpsMixin.value_counts of 0       139.0\n",
      "1       126.0\n",
      "2        69.0\n",
      "3         2.0\n",
      "4        17.0\n",
      "        ...  \n",
      "1592      9.0\n",
      "1593     41.0\n",
      "1594     34.0\n",
      "1595      7.0\n",
      "1596     10.0\n",
      "Name: reviews.numHelpful, Length: 1597, dtype: float64>\n",
      "\n",
      "\n",
      "reviews.rating:\t<bound method IndexOpsMixin.value_counts of 0       5.0\n",
      "1       5.0\n",
      "2       4.0\n",
      "3       5.0\n",
      "4       5.0\n",
      "       ... \n",
      "1592    3.0\n",
      "1593    1.0\n",
      "1594    1.0\n",
      "1595    3.0\n",
      "1596    1.0\n",
      "Name: reviews.rating, Length: 1597, dtype: float64>\n",
      "\n",
      "\n",
      "reviews.sourceURLs:\t<bound method IndexOpsMixin.value_counts of 0       https:\/\/www.amazon.com\/Kindle-Paperwhite-High-...\n",
      "1       https:\/\/www.amazon.com\/Kindle-Paperwhite-High-...\n",
      "2       https:\/\/www.amazon.com\/Kindle-Paperwhite-High-...\n",
      "3       https:\/\/www.amazon.com\/Kindle-Paperwhite-High-...\n",
      "4       https:\/\/www.amazon.com\/Kindle-Paperwhite-High-...\n",
      "                              ...                        \n",
      "1592    https:\/\/www.amazon.com\/Alexa-Voice-Remote-Amaz...\n",
      "1593    https:\/\/www.amazon.com\/Alexa-Voice-Remote-Amaz...\n",
      "1594    https:\/\/www.amazon.com\/Alexa-Voice-Remote-Amaz...\n",
      "1595    https:\/\/www.amazon.com\/Alexa-Voice-Remote-Amaz...\n",
      "1596    https:\/\/www.amazon.com\/Alexa-Voice-Remote-Amaz...\n",
      "Name: reviews.sourceURLs, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "reviews.text:\t<bound method IndexOpsMixin.value_counts of 0       I initially had trouble deciding between the p...\n",
      "1       Allow me to preface this with a little history...\n",
      "2       I am enjoying it so far. Great for reading. Ha...\n",
      "3       I bought one of the first Paperwhites and have...\n",
      "4       I have to say upfront - I don't like coroporat...\n",
      "                              ...                        \n",
      "1592    This is not the same remote that I got for my ...\n",
      "1593    I have had to change the batteries in this rem...\n",
      "1594    Remote did not activate, nor did it connect to...\n",
      "1595    It does the job but is super over priced. I fe...\n",
      "1596    I ordered this item to replace the one that no...\n",
      "Name: reviews.text, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "reviews.title:\t<bound method IndexOpsMixin.value_counts of 0                          Paperwhite voyage, no regrets!\n",
      "1                       One Simply Could Not Ask For More\n",
      "2              Great for those that just want an e-reader\n",
      "3                                Love \/ Hate relationship\n",
      "4                                               I LOVE IT\n",
      "                              ...                        \n",
      "1592    I would be disappointed with myself if i produ...\n",
      "1593                          Battery draining remote!!!!\n",
      "1594        replacing an even worse remote. Waste of time\n",
      "1595                                           Overpriced\n",
      "1596    I am sending all of this crap back to amazon a...\n",
      "Name: reviews.title, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "reviews.userCity:\t<bound method IndexOpsMixin.value_counts of 0      NaN\n",
      "1      NaN\n",
      "2      NaN\n",
      "3      NaN\n",
      "4      NaN\n",
      "        ..\n",
      "1592   NaN\n",
      "1593   NaN\n",
      "1594   NaN\n",
      "1595   NaN\n",
      "1596   NaN\n",
      "Name: reviews.userCity, Length: 1597, dtype: float64>\n",
      "\n",
      "\n",
      "reviews.userProvince:\t<bound method IndexOpsMixin.value_counts of 0      NaN\n",
      "1      NaN\n",
      "2      NaN\n",
      "3      NaN\n",
      "4      NaN\n",
      "        ..\n",
      "1592   NaN\n",
      "1593   NaN\n",
      "1594   NaN\n",
      "1595   NaN\n",
      "1596   NaN\n",
      "Name: reviews.userProvince, Length: 1597, dtype: float64>\n",
      "\n",
      "\n",
      "reviews.username:\t<bound method IndexOpsMixin.value_counts of 0               Cristina M\n",
      "1                    Ricky\n",
      "2            Tedd Gardiner\n",
      "3                   Dougal\n",
      "4       Miljan David Tanic\n",
      "               ...        \n",
      "1592       GregAmandawith4\n",
      "1593       Amazon Customer\n",
      "1594       Amazon Customer\n",
      "1595            Meg Ashley\n",
      "1596               DIANE K\n",
      "Name: reviews.username, Length: 1597, dtype: object>\n",
      "\n",
      "\n",
      "sizes:\t<bound method IndexOpsMixin.value_counts of 0      NaN\n",
      "1      NaN\n",
      "2      NaN\n",
      "3      NaN\n",
      "4      NaN\n",
      "        ..\n",
      "1592   NaN\n",
      "1593   NaN\n",
      "1594   NaN\n",
      "1595   NaN\n",
      "1596   NaN\n",
      "Name: sizes, Length: 1597, dtype: float64>\n",
      "\n",
      "\n",
      "upc:\t<bound method IndexOpsMixin.value_counts of 0      NaN\n",
      "1      NaN\n",
      "2      NaN\n",
      "3      NaN\n",
      "4      NaN\n",
      "        ..\n",
      "1592   NaN\n",
      "1593   NaN\n",
      "1594   NaN\n",
      "1595   NaN\n",
      "1596   NaN\n",
      "Name: upc, Length: 1597, dtype: float64>\n",
      "\n",
      "\n",
      "weight:\t<bound method IndexOpsMixin.value_counts of 0       205 grams\n",
      "1       205 grams\n",
      "2       205 grams\n",
      "3       205 grams\n",
      "4       205 grams\n",
      "          ...    \n",
      "1592     4 ounces\n",
      "1593     4 ounces\n",
      "1594     4 ounces\n",
      "1595     4 ounces\n",
      "1596     4 ounces\n",
      "Name: weight, Length: 1597, dtype: object>\n",
      "\n",
      "\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"AOrFilVWDMVJJfvsryP1r4"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Drop NaN values and create train_and_target_data\n",
    "\n",
    "# Will drop all columns exept for the review title and text\n",
    "train_and_target_data = dataset_full[[\"reviews.title\", \"reviews.text\", \"reviews.rating\"]]\n",
    "train_and_target_data = train_and_target_data.dropna()\n",
    "\n",
    "clean_data_train = train_and_target_data[[\"reviews.title\", \"reviews.text\"]]\n",
    "clean_data_train.head(10)"
   ],
   "execution_count":9,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>reviews.title<\/th>\n",
       "      <th>reviews.text<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>Paperwhite voyage, no regrets!<\/td>\n",
       "      <td>I initially had trouble deciding between the p...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>One Simply Could Not Ask For More<\/td>\n",
       "      <td>Allow me to preface this with a little history...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>Great for those that just want an e-reader<\/td>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>3<\/th>\n",
       "      <td>Love \/ Hate relationship<\/td>\n",
       "      <td>I bought one of the first Paperwhites and have...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>4<\/th>\n",
       "      <td>I LOVE IT<\/td>\n",
       "      <td>I have to say upfront - I don't like coroporat...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>13<\/th>\n",
       "      <td>Liked the smaller size<\/td>\n",
       "      <td>Had older model, that you could text to speech...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>14<\/th>\n",
       "      <td>Superb reading device - but which one's best f...<\/td>\n",
       "      <td>This is a review of the Kindle Paperwhite laun...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>15<\/th>\n",
       "      <td>I love it!<\/td>\n",
       "      <td>I love my kindle! I got one for my fiance on h...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>16<\/th>\n",
       "      <td>Un plaisir<\/td>\n",
       "      <td>Vraiment bon petit appareil , lger et facile d...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>17<\/th>\n",
       "      <td>Works great and I love the built-in light<\/td>\n",
       "      <td>Exactly what it is supposed to be. Works great...<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"5PsJ251dWxxSEgOUdhE5AT"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Create test data\n",
    "\n",
    "clean_data_test = train_and_target_data[\"reviews.rating\"]\n",
    "clean_data_test.head(10)"
   ],
   "execution_count":10,
   "outputs":[
    {
     "data":{
      "text\/html":[
       
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"YgnEzzylYvGw5VFdEfaQNi"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import plotly.express as px\n",
    "px.histogram(data_frame=clean_data_test)"
   ],
   "execution_count":11,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "Unsupported"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"0U7cjLBRwKI1048NXgWuqa"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "print(\n",
    "    f\"Ratio of Non-NaN vals in ratings to total vals: {len(clean_data_test.dropna())\/len(clean_data_test)}\"\n",
    ")"
   ],
   "execution_count":12,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Ratio of Non-NaN vals in ratings to total vals: 1.0\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"jwSfPv7zV4vibKXtF54CX6"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(clean_data_train.to_numpy(),\n",
    "                                                                            clean_data_test.to_numpy(),\n",
    "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
    "                                                                            random_state=42) # random state for reproducibility\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Currently, X_train and X_test are arrays with two features: The title of the review and the description\n",
    "# It would be appropriate to simply join the title with the description.\n",
    "\n",
    "\n",
    "\n",
    "# Input: np.ndarray -> Output: np.ndarray\n",
    "def join_titles_sentences(data_np):\n",
    "    new_data = np.array(list(\n",
    "    '. '.join(str(feature) for feature in review) for review in data_np\n",
    "))\n",
    "    return new_data\n",
    "\n",
    "x_train = join_titles_sentences(train_sentences)\n",
    "print(f\"INFO OF x_train:\\n\\t {np.info(x_train)}\\n\")\n",
    "print(f\"FIRST SAMPLE OF x_train:\\n\\t {x_train[0]}\\n\")\n",
    "print(f\"SHAPE OF FIRST SAMPLE:\\t\\n{x_train[0].shape}\")\n",
    "y_train = train_labels\n",
    "print(f\"INFO OF y_train:\\n\\t {np.info(y_train)}\\n\")\n",
    "print(f\"FIRST SAMPLE OF y_train:\\n\\t {y_train[0]}\\n\")\n",
    "print(f\"SHAPE OF FIRST SAMPLE:\\t\\n{y_train[0].shape}\")\n",
    "\n",
    "print(np.info(x_train), '\\n')\n",
    "print(x_train[0], '\\n')\n"
   ],
   "execution_count":13,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "class:  ndarray\n",
      "shape:  (1059,)\n",
      "strides:  (79408,)\n",
      "itemsize:  79408\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  True\n",
      "data pointer: 0x7fae1e3eb010\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: <U19852\n",
      "INFO OF x_train:\n",
      "\t None\n",
      "\n",
      "FIRST SAMPLE OF x_train:\n",
      "\t Amazon Tap brings a new meaning to portable music. Amazon Echo is great. But it is stuck at home. Amazon Tap on the other hand goes everywhere. In the short time we have had ours, we have brought it to Sweden, Portugal, the lake up north and friend's houses. It has served as a music host at card games, answered questions and added things to our shopping list. It is easy to set up Amazon Tap to a wifi network using the Alexa app on your smartphone. You can also easily pair several devices to the Tap via Bluetooth. What really makes this device great is that the cloud based software is continually updated. New skills and capabilities are made available on a regular basis. Amazon really hit home with the Tap as the voice interface is so easy to use, and the portability makes it a great.\n",
      "\n",
      "SHAPE OF FIRST SAMPLE:\t\n",
      "()\n",
      "class:  ndarray\n",
      "shape:  (1059,)\n",
      "strides:  (8,)\n",
      "itemsize:  8\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  True\n",
      "data pointer: 0x55c933923fa0\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: float64\n",
      "INFO OF y_train:\n",
      "\t None\n",
      "\n",
      "FIRST SAMPLE OF y_train:\n",
      "\t 5.0\n",
      "\n",
      "SHAPE OF FIRST SAMPLE:\t\n",
      "()\n",
      "class:  ndarray\n",
      "shape:  (1059,)\n",
      "strides:  (79408,)\n",
      "itemsize:  79408\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  True\n",
      "data pointer: 0x7fae1e3eb010\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: <U19852\n",
      "None \n",
      "\n",
      "Amazon Tap brings a new meaning to portable music. Amazon Echo is great. But it is stuck at home. Amazon Tap on the other hand goes everywhere. In the short time we have had ours, we have brought it to Sweden, Portugal, the lake up north and friend's houses. It has served as a music host at card games, answered questions and added things to our shopping list. It is easy to set up Amazon Tap to a wifi network using the Alexa app on your smartphone. You can also easily pair several devices to the Tap via Bluetooth. What really makes this device great is that the cloud based software is continually updated. New skills and capabilities are made available on a regular basis. Amazon really hit home with the Tap as the voice interface is so easy to use, and the portability makes it a great. \n",
      "\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"b1CH5wlpv6Ktd6RqPISvtc"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Embedding\n",
    "\n",
    "MAX_TOKENS = 2**13\n",
    "MAX_SEQ_LENGTH = 20\n",
    "OOV_TOKEN = \"<OOV>\"\n",
    "\n",
    "def texts_to_seq(train_data, method=\"tokenizer\"):\n",
    "\n",
    "    '''\n",
    "\n",
    "    Returns the given text dataset into a sequence dataset.\n",
    "\n",
    "    Parameters: \n",
    "        train_data - the training text to train on\n",
    "        method: ∈ {\"tokenizer\"} - the method by which to convert to sequence\n",
    "    '''\n",
    "\n",
    "    if method==\"tokenizer\":\n",
    "        from keras.preprocessing.text import Tokenizer\n",
    "        from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "        tokenizer_one = Tokenizer(\n",
    "        num_words=MAX_TOKENS,\n",
    "        oov_token=OOV_TOKEN\n",
    "        )\n",
    "\n",
    "        tokenizer_one.fit_on_texts(train_data)\n",
    "\n",
    "        without_padding_data = tokenizer_one.texts_to_sequences(train_data)\n",
    "        return pad_sequences(without_padding_data, 200)"
   ],
   "execution_count":14,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"04F4nYJrQD6XsciZ42CH4x"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Make a naive bayes baseline classifier;\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "naive_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"classifier\", MultinomialNB())\n",
    "])\n",
    "\n",
    "model_0 = naive_pipeline.fit(x_train, train_labels)\n",
    "baseline_score = model_0.score(x_train, y_train)\n",
    "baseline_score"
   ],
   "execution_count":15,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "0.6685552407932012"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"yl6cT44GvEvFnqLwtYMTDD"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# make a function to evaluate with fscores, precision, recall\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import math\n",
    "\n",
    "# np.ndarray -> np.ndarray\n",
    "def score_fscore_precision_recall(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\n",
    "        \"accuracy\":accuracy,\n",
    "        \"model precision\":model_precision,\n",
    "        \"model recall\": model_recall,\n",
    "        \"model F1 score\": model_f1,\n",
    "        \"mean score\": np.mean([accuracy, model_precision, model_recall, model_f1])\n",
    "    }\n",
    "    return model_results"
   ],
   "execution_count":16,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"Qxbxc52Ic7WiC898j0P6fQ"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "score_fscore_precision_recall(model_0.predict(x_train), y_train)"
   ],
   "execution_count":17,
   "outputs":[
    {
     "name":"stderr",
     "text":[
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/sklearn\/metrics\/_classification.py:1308: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      "text\/plain":[
       "{'accuracy': 0.6685552407932012,\n",
       " 'model precision': 0.9763162958885474,\n",
       " 'model recall': 0.6685552407932012,\n",
       " 'model F1 score': 0.7813679711816148,\n",
       " 'mean score': 0.7736986871641411}"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"ycxr1F3ZuzAtvIjFFJ94I6"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Make a model one (dense model)\n",
    "\n",
    "## Important layers    \n",
    "\n",
    "embedding_layer_one = Embedding(\n",
    "    input_dim=MAX_TOKENS,\n",
    "    output_dim=128,\n",
    "    input_length=200,\n",
    "    name=\"embedding_one\"\n",
    ")"
   ],
   "execution_count":18,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"EWFcL6WX4V9E4fj7QopK3E"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Model 1 - Dense Model\n",
    "'''x = texts_to_seq(inputs)\n",
    "x = embedding_layer_one(x)\n",
    "x = keras.layers.GlobalAveragePooling1D()(x)\n",
    "outputs = keras.layers.Dense(5, activation=\"softmax\")(x)\n",
    "model_1 = keras.models.Model(inputs=inputs, outputs=outputs, name=\"model_1\")\n",
    "\n",
    "'''\n",
    "\n",
    "model_1 = keras.models.Sequential([\n",
    "    embedding_layer_one,\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(12)),\n",
    "    keras.layers.Dense(6, activation=\"softmax\")\n",
    "])"
   ],
   "execution_count":19,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"ockGxLK2lXXXcEDK8qbaHy"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "def preprocess_seq(train_x, test_x):\n",
    "\n",
    "    return tf.cast(texts_to_seq(train_x), tf.int32), test_x\n",
    "\n",
    "preprocessed_x_train, preprocessed_y_train = preprocess_seq(x_train, y_train)\n",
    "print(preprocessed_x_train[0])\n",
    "print(preprocessed_y_train[0])\n",
    "np.info(np.array(preprocessed_x_train))"
   ],
   "execution_count":20,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "tf.Tensor(\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0   25   65 2967    6\n",
      "   72 1602    3  223  100   25   59    8   23   17    7    8 1692   36\n",
      "  221   25   65   18    2  105  830  966 2186   15    2  450   95  119\n",
      "   19   76 3757  119   19 1174    7    3 3758 3759    2 2968   71 3760\n",
      "    5 3761 2969    7   53 2515   20    6  100 2970   36  831  367 1693\n",
      "  427    5  342  138    3  265 1031  571    7    8  107    3  167   71\n",
      "   25   65    3    6  308 1235  115    2   91  172   18   43  491   12\n",
      "   34   85  362  439  399  227    3    2   65  508  222   89   87  428\n",
      "   11   63   23    8   13    2  538  752  382    8 2516  378   72 1694\n",
      "    5 1000   22  293  243   18    6  345 1309   25   87  967  221   16\n",
      "    2   65   20    2  163  480    8   26  107    3   40    5    2  492\n",
      "  428    7    6   23], shape=(200,), dtype=int32)\n",
      "5.0\n",
      "class:  ndarray\n",
      "shape:  (1059, 200)\n",
      "strides:  (800, 4)\n",
      "itemsize:  4\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  False\n",
      "data pointer: 0x55c937a0c9d0\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: int32\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"DcD0cYomDMFPIp8W0Noufq"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "val_sent, val_lab = preprocess_seq(join_titles_sentences(val_sentences), val_labels)"
   ],
   "execution_count":21,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"4EhMyxVTI4N79uoJclSYeG"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "model_1.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, nesterov=True, momentum=0.99), metrics=['accuracy'])"
   ],
   "execution_count":22,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"ydueK51jafLtUmdDvpXGWQ"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "\n",
    "val_sent, val_lab = preprocess_seq(join_titles_sentences(val_sentences), val_labels)\n",
    "history = model_1.fit(preprocessed_x_train, y_train, epochs=5, validation_data=(val_sent, val_lab))\n"
   ],
   "execution_count":23,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Epoch 1\/5\n",
      "\r 1\/34 [..............................] - ETA: 12:18 - loss: 1.7923 - accuracy: 0.2188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2\/34 [>.............................] - ETA: 49s - loss: 1.7649 - accuracy: 0.4688  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3\/34 [=>............................] - ETA: 44s - loss: 1.7328 - accuracy: 0.5521\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4\/34 [==>...........................] - ETA: 41s - loss: 1.7086 - accuracy: 0.5469\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5\/34 [===>..........................] - ETA: 39s - loss: 1.6759 - accuracy: 0.5625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6\/34 [====>.........................] - ETA: 37s - loss: 1.6564 - accuracy: 0.5521\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7\/34 [=====>........................] - ETA: 36s - loss: 1.6262 - accuracy: 0.5625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8\/34 [======>.......................] - ETA: 35s - loss: 1.6099 - accuracy: 0.5625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9\/34 [======>.......................] - ETA: 33s - loss: 1.5795 - accuracy: 0.5694\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10\/34 [=======>......................] - ETA: 32s - loss: 1.5448 - accuracy: 0.5844\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11\/34 [========>.....................] - ETA: 30s - loss: 1.5115 - accuracy: 0.5909\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12\/34 [=========>....................] - ETA: 29s - loss: 1.4807 - accuracy: 0.5964\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13\/34 [==========>...................] - ETA: 28s - loss: 1.4806 - accuracy: 0.5841\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14\/34 [===========>..................] - ETA: 26s - loss: 1.4739 - accuracy: 0.5804\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15\/34 [============>.................] - ETA: 25s - loss: 1.4611 - accuracy: 0.5792\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16\/34 [=============>................] - ETA: 22s - loss: 1.4450 - accuracy: 0.5820\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17\/34 [==============>...............] - ETA: 20s - loss: 1.4121 - accuracy: 0.5919\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18\/34 [==============>...............] - ETA: 18s - loss: 1.3832 - accuracy: 0.6024\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19\/34 [===============>..............] - ETA: 16s - loss: 1.3591 - accuracy: 0.6086\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20\/34 [================>.............] - ETA: 14s - loss: 1.3337 - accuracy: 0.6156\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21\/34 [=================>............] - ETA: 12s - loss: 1.3441 - accuracy: 0.6086\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22\/34 [==================>...........] - ETA: 11s - loss: 1.3549 - accuracy: 0.6023\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23\/34 [===================>..........] - ETA: 10s - loss: 1.3410 - accuracy: 0.6060\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24\/34 [====================>.........] - ETA: 8s - loss: 1.3283 - accuracy: 0.6094 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25\/34 [=====================>........] - ETA: 7s - loss: 1.3308 - accuracy: 0.6050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r26\/34 [=====================>........] - ETA: 6s - loss: 1.3127 - accuracy: 0.6106\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27\/34 [======================>.......] - ETA: 5s - loss: 1.3090 - accuracy: 0.6111\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/34 [=======================>......] - ETA: 4s - loss: 1.2984 - accuracy: 0.6138\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29\/34 [========================>.....] - ETA: 3s - loss: 1.2831 - accuracy: 0.6164\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30\/34 [=========================>....] - ETA: 3s - loss: 1.2763 - accuracy: 0.6167\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31\/34 [==========================>...] - ETA: 2s - loss: 1.2714 - accuracy: 0.6149\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32\/34 [===========================>..] - ETA: 1s - loss: 1.2538 - accuracy: 0.6211\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33\/34 [============================>.] - ETA: 0s - loss: 1.2542 - accuracy: 0.6222\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34\/34 [==============================] - ETA: 0s - loss: 1.2519 - accuracy: 0.6232\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34\/34 [==============================] - 47s 749ms\/step - loss: 1.2519 - accuracy: 0.6232 - val_loss: 1.2536 - val_accuracy: 0.5763\n",
      "Epoch 2\/5\n",
      "\r 1\/34 [..............................] - ETA: 7s - loss: 1.1024 - accuracy: 0.6875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2\/34 [>.............................] - ETA: 7s - loss: 1.1086 - accuracy: 0.5938\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3\/34 [=>............................] - ETA: 7s - loss: 1.0185 - accuracy: 0.6458\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4\/34 [==>...........................] - ETA: 7s - loss: 0.9983 - accuracy: 0.6641\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5\/34 [===>..........................] - ETA: 6s - loss: 1.0174 - accuracy: 0.6500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6\/34 [====>.........................] - ETA: 6s - loss: 0.9773 - accuracy: 0.6615\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7\/34 [=====>........................] - ETA: 6s - loss: 1.0017 - accuracy: 0.6607\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8\/34 [======>.......................] - ETA: 6s - loss: 1.0257 - accuracy: 0.6484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9\/34 [======>.......................] - ETA: 5s - loss: 1.0554 - accuracy: 0.6354\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10\/34 [=======>......................] - ETA: 5s - loss: 1.0237 - accuracy: 0.6531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11\/34 [========>.....................] - ETA: 5s - loss: 1.0580 - accuracy: 0.6449\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12\/34 [=========>....................] - ETA: 5s - loss: 1.0525 - accuracy: 0.6458\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13\/34 [==========>...................] - ETA: 4s - loss: 1.0643 - accuracy: 0.6370\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14\/34 [===========>..................] - ETA: 4s - loss: 1.0466 - accuracy: 0.6451\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15\/34 [============>.................] - ETA: 4s - loss: 1.0258 - accuracy: 0.6521\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16\/34 [=============>................] - ETA: 4s - loss: 1.0394 - accuracy: 0.6504\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17\/34 [==============>...............] - ETA: 3s - loss: 1.0437 - accuracy: 0.6452\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18\/34 [==============>...............] - ETA: 3s - loss: 1.0331 - accuracy: 0.6510\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19\/34 [===============>..............] - ETA: 3s - loss: 1.0609 - accuracy: 0.6382\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20\/34 [================>.............] - ETA: 3s - loss: 1.0760 - accuracy: 0.6328\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21\/34 [=================>............] - ETA: 3s - loss: 1.0765 - accuracy: 0.6369\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22\/34 [==================>...........] - ETA: 2s - loss: 1.0925 - accuracy: 0.6321\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23\/34 [===================>..........] - ETA: 2s - loss: 1.0913 - accuracy: 0.6318\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24\/34 [====================>.........] - ETA: 2s - loss: 1.0769 - accuracy: 0.6380\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25\/34 [=====================>........] - ETA: 2s - loss: 1.0860 - accuracy: 0.6338\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r26\/34 [=====================>........] - ETA: 1s - loss: 1.0948 - accuracy: 0.6298\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27\/34 [======================>.......] - ETA: 1s - loss: 1.0919 - accuracy: 0.6296\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/34 [=======================>......] - ETA: 1s - loss: 1.0870 - accuracy: 0.6306\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29\/34 [========================>.....] - ETA: 1s - loss: 1.0841 - accuracy: 0.6325\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30\/34 [=========================>....] - ETA: 0s - loss: 1.0865 - accuracy: 0.6313\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31\/34 [==========================>...] - ETA: 0s - loss: 1.0893 - accuracy: 0.6321\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32\/34 [===========================>..] - ETA: 0s - loss: 1.0955 - accuracy: 0.6279\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33\/34 [============================>.] - ETA: 0s - loss: 1.0816 - accuracy: 0.6354\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34\/34 [==============================] - ETA: 0s - loss: 1.0810 - accuracy: 0.6355\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34\/34 [==============================] - 8s 238ms\/step - loss: 1.0810 - accuracy: 0.6355 - val_loss: 1.2180 - val_accuracy: 0.5763\n",
      "Epoch 3\/5\n",
      "\r 1\/34 [..............................] - ETA: 7s - loss: 0.9548 - accuracy: 0.6562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2\/34 [>.............................] - ETA: 7s - loss: 1.0182 - accuracy: 0.6094\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3\/34 [=>............................] - ETA: 7s - loss: 1.0674 - accuracy: 0.6146\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4\/34 [==>...........................] - ETA: 6s - loss: 1.0614 - accuracy: 0.6172\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5\/34 [===>..........................] - ETA: 6s - loss: 1.1055 - accuracy: 0.6062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6\/34 [====>.........................] - ETA: 6s - loss: 1.1368 - accuracy: 0.5938\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7\/34 [=====>........................] - ETA: 6s - loss: 1.0925 - accuracy: 0.6205\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8\/34 [======>.......................] - ETA: 5s - loss: 1.0899 - accuracy: 0.6211\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9\/34 [======>.......................] - ETA: 5s - loss: 1.0833 - accuracy: 0.6250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10\/34 [=======>......................] - ETA: 5s - loss: 1.0682 - accuracy: 0.6344\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11\/34 [========>.....................] - ETA: 5s - loss: 1.0699 - accuracy: 0.6307\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12\/34 [=========>....................] - ETA: 5s - loss: 1.0768 - accuracy: 0.6276\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13\/34 [==========>...................] - ETA: 4s - loss: 1.0658 - accuracy: 0.6370\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14\/34 [===========>..................] - ETA: 4s - loss: 1.0575 - accuracy: 0.6384\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15\/34 [============>.................] - ETA: 4s - loss: 1.0510 - accuracy: 0.6438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16\/34 [=============>................] - ETA: 4s - loss: 1.0480 - accuracy: 0.6465\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17\/34 [==============>...............] - ETA: 3s - loss: 1.0519 - accuracy: 0.6452\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18\/34 [==============>...............] - ETA: 3s - loss: 1.0573 - accuracy: 0.6441\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19\/34 [===============>..............] - ETA: 3s - loss: 1.0620 - accuracy: 0.6431\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20\/34 [================>.............] - ETA: 3s - loss: 1.0509 - accuracy: 0.6484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21\/34 [=================>............] - ETA: 3s - loss: 1.0579 - accuracy: 0.6429\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22\/34 [==================>...........] - ETA: 2s - loss: 1.0550 - accuracy: 0.6435\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23\/34 [===================>..........] - ETA: 2s - loss: 1.0644 - accuracy: 0.6399\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24\/34 [====================>.........] - ETA: 2s - loss: 1.0655 - accuracy: 0.6393\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25\/34 [=====================>........] - ETA: 2s - loss: 1.0652 - accuracy: 0.6413\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r26\/34 [=====================>........] - ETA: 1s - loss: 1.0671 - accuracy: 0.6394\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27\/34 [======================>.......] - ETA: 1s - loss: 1.0682 - accuracy: 0.6400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/34 [=======================>......] - ETA: 1s - loss: 1.0623 - accuracy: 0.6417\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29\/34 [========================>.....] - ETA: 1s - loss: 1.0540 - accuracy: 0.6444\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30\/34 [=========================>....] - ETA: 0s - loss: 1.0580 - accuracy: 0.6417\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31\/34 [==========================>...] - ETA: 0s - loss: 1.0625 - accuracy: 0.6411\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32\/34 [===========================>..] - ETA: 0s - loss: 1.0679 - accuracy: 0.6377\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33\/34 [============================>.] - ETA: 0s - loss: 1.0666 - accuracy: 0.6364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34\/34 [==============================] - ETA: 0s - loss: 1.0671 - accuracy: 0.6355\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34\/34 [==============================] - 8s 239ms\/step - loss: 1.0671 - accuracy: 0.6355 - val_loss: 1.1938 - val_accuracy: 0.5763\n",
      "Epoch 4\/5\n",
      "\r 1\/34 [..............................] - ETA: 8s - loss: 0.9591 - accuracy: 0.7188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2\/34 [>.............................] - ETA: 7s - loss: 1.0393 - accuracy: 0.6875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3\/34 [=>............................] - ETA: 7s - loss: 0.9802 - accuracy: 0.6875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4\/34 [==>...........................] - ETA: 7s - loss: 1.0299 - accuracy: 0.6406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5\/34 [===>..........................] - ETA: 7s - loss: 1.0175 - accuracy: 0.6562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6\/34 [====>.........................] - ETA: 6s - loss: 1.0238 - accuracy: 0.6562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7\/34 [=====>........................] - ETA: 6s - loss: 1.0133 - accuracy: 0.6652\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8\/34 [======>.......................] - ETA: 6s - loss: 1.0221 - accuracy: 0.6523\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9\/34 [======>.......................] - ETA: 6s - loss: 1.0231 - accuracy: 0.6597\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10\/34 [=======>......................] - ETA: 5s - loss: 1.0314 - accuracy: 0.6594\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11\/34 [========>.....................] - ETA: 5s - loss: 1.0241 - accuracy: 0.6591\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12\/34 [=========>....................] - ETA: 5s - loss: 1.0262 - accuracy: 0.6641\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13\/34 [==========>...................] - ETA: 5s - loss: 1.0174 - accuracy: 0.6707\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14\/34 [===========>..................] - ETA: 4s - loss: 1.0298 - accuracy: 0.6629\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15\/34 [============>.................] - ETA: 4s - loss: 1.0220 - accuracy: 0.6646\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16\/34 [=============>................] - ETA: 4s - loss: 1.0579 - accuracy: 0.6543\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17\/34 [==============>...............] - ETA: 4s - loss: 1.0458 - accuracy: 0.6581\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18\/34 [==============>...............] - ETA: 3s - loss: 1.0572 - accuracy: 0.6545\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19\/34 [===============>..............] - ETA: 3s - loss: 1.0721 - accuracy: 0.6480\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20\/34 [================>.............] - ETA: 3s - loss: 1.0712 - accuracy: 0.6453\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21\/34 [=================>............] - ETA: 3s - loss: 1.0582 - accuracy: 0.6503\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22\/34 [==================>...........] - ETA: 2s - loss: 1.0588 - accuracy: 0.6477\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23\/34 [===================>..........] - ETA: 2s - loss: 1.0733 - accuracy: 0.6467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24\/34 [====================>.........] - ETA: 2s - loss: 1.0798 - accuracy: 0.6445\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25\/34 [=====================>........] - ETA: 2s - loss: 1.0797 - accuracy: 0.6438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r26\/34 [=====================>........] - ETA: 1s - loss: 1.0943 - accuracy: 0.6358\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27\/34 [======================>.......] - ETA: 1s - loss: 1.0920 - accuracy: 0.6331\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/34 [=======================>......] - ETA: 1s - loss: 1.0910 - accuracy: 0.6339\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29\/34 [========================>.....] - ETA: 1s - loss: 1.0859 - accuracy: 0.6347\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30\/34 [=========================>....] - ETA: 0s - loss: 1.0851 - accuracy: 0.6344\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31\/34 [==========================>...] - ETA: 0s - loss: 1.0791 - accuracy: 0.6361\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32\/34 [===========================>..] - ETA: 0s - loss: 1.0765 - accuracy: 0.6377\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33\/34 [============================>.] - ETA: 0s - loss: 1.0824 - accuracy: 0.6345\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34\/34 [==============================] - ETA: 0s - loss: 1.0805 - accuracy: 0.6355\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34\/34 [==============================] - 8s 241ms\/step - loss: 1.0805 - accuracy: 0.6355 - val_loss: 1.2039 - val_accuracy: 0.5763\n",
      "Epoch 5\/5\n",
      "\r 1\/34 [..............................] - ETA: 7s - loss: 1.4770 - accuracy: 0.5000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2\/34 [>.............................] - ETA: 7s - loss: 1.2980 - accuracy: 0.5469\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3\/34 [=>............................] - ETA: 7s - loss: 1.2042 - accuracy: 0.5833\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4\/34 [==>...........................] - ETA: 7s - loss: 1.2041 - accuracy: 0.5938\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5\/34 [===>..........................] - ETA: 6s - loss: 1.1263 - accuracy: 0.6187\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6\/34 [====>.........................] - ETA: 6s - loss: 1.0812 - accuracy: 0.6354\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7\/34 [=====>........................] - ETA: 6s - loss: 1.1286 - accuracy: 0.6161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8\/34 [======>.......................] - ETA: 6s - loss: 1.1070 - accuracy: 0.6250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9\/34 [======>.......................] - ETA: 5s - loss: 1.0671 - accuracy: 0.6424\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10\/34 [=======>......................] - ETA: 5s - loss: 1.0895 - accuracy: 0.6281\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11\/34 [========>.....................] - ETA: 5s - loss: 1.0886 - accuracy: 0.6278\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r12\/34 [=========>....................] - ETA: 5s - loss: 1.0797 - accuracy: 0.6302\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13\/34 [==========>...................] - ETA: 4s - loss: 1.0618 - accuracy: 0.6394\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14\/34 [===========>..................] - ETA: 4s - loss: 1.0692 - accuracy: 0.6339\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15\/34 [============>.................] - ETA: 4s - loss: 1.0641 - accuracy: 0.6333\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16\/34 [=============>................] - ETA: 4s - loss: 1.0537 - accuracy: 0.6387\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r17\/34 [==============>...............] - ETA: 3s - loss: 1.0526 - accuracy: 0.6397\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r18\/34 [==============>...............] - ETA: 3s - loss: 1.0530 - accuracy: 0.6372\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r19\/34 [===============>..............] - ETA: 3s - loss: 1.0427 - accuracy: 0.6431\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20\/34 [================>.............] - ETA: 3s - loss: 1.0503 - accuracy: 0.6375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r21\/34 [=================>............] - ETA: 3s - loss: 1.0539 - accuracy: 0.6354\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22\/34 [==================>...........] - ETA: 2s - loss: 1.0475 - accuracy: 0.6406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r23\/34 [===================>..........] - ETA: 2s - loss: 1.0451 - accuracy: 0.6427\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24\/34 [====================>.........] - ETA: 2s - loss: 1.0528 - accuracy: 0.6406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25\/34 [=====================>........] - ETA: 2s - loss: 1.0489 - accuracy: 0.6438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r26\/34 [=====================>........] - ETA: 1s - loss: 1.0589 - accuracy: 0.6382\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27\/34 [======================>.......] - ETA: 1s - loss: 1.0583 - accuracy: 0.6400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r28\/34 [=======================>......] - ETA: 1s - loss: 1.0599 - accuracy: 0.6373\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r29\/34 [========================>.....] - ETA: 1s - loss: 1.0558 - accuracy: 0.6390\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30\/34 [=========================>....] - ETA: 0s - loss: 1.0504 - accuracy: 0.6417\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r31\/34 [==========================>...] - ETA: 0s - loss: 1.0536 - accuracy: 0.6391\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32\/34 [===========================>..] - ETA: 0s - loss: 1.0602 - accuracy: 0.6367\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r33\/34 [============================>.] - ETA: 0s - loss: 1.0604 - accuracy: 0.6354\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34\/34 [==============================] - ETA: 0s - loss: 1.0599 - accuracy: 0.6355\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34\/34 [==============================] - 8s 239ms\/step - loss: 1.0599 - accuracy: 0.6355 - val_loss: 1.2010 - val_accuracy: 0.5763\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"CAGhCvBcfr02nIZYrOqoHK"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "px.line(history.history, range_y=[0.3, 1])"
   ],
   "execution_count":24,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "Unsupported"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"cV53lk2UOUohvh13CgXQc5"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "test_example = preprocess_seq([\"This was a rubbish piece of product. Please do not buy. It is trash. Hate it.\"], _)\n",
    "model_1.predict(tf.Variable([1]))"
   ],
   "execution_count":25,
   "outputs":[
    {
     "ename":"ValueError",
     "evalue":"ValueError: Failed to find data adapter that can handle input: <class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>, <class 'NoneType'>",
     "traceback":[
      "\u001b[0;31m---------------------------------------------------------------------------",
      "Traceback (most recent call last)",
      "    at line 2 in <module>",
      "    at line 67 in error_handler(*args, **kwargs)",
      "    at line 988 in select_data_adapter(x, y)",
      "ValueError: Failed to find data adapter that can handle input: <class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>, <class 'NoneType'>"
     ],
     "output_type":"error"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"oOaTnFkLEEUzg93kq8gx2o"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "pip install tensorflow-hub"
   ],
   "execution_count":114,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Collecting tensorflow-hub\r\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\r\n",
      "\u001b[?25l\r\r     |███                             | 10 kB 24.3 MB\/s eta 0:00:01\r     |██████                          | 20 kB 28.2 MB\/s eta 0:00:01\r     |█████████                       | 30 kB 31.7 MB\/s eta 0:00:01\r     |████████████                    | 40 kB 34.7 MB\/s eta 0:00:01\r     |███████████████                 | 51 kB 26.4 MB\/s eta 0:00:01\r     |██████████████████              | 61 kB 29.6 MB\/s eta 0:00:01\r     |█████████████████████           | 71 kB 32.1 MB\/s eta 0:00:01\r     |████████████████████████        | 81 kB 34.3 MB\/s eta 0:00:01\r     |███████████████████████████     | 92 kB 36.6 MB\/s eta 0:00:01\r     |██████████████████████████████▏ | 102 kB 38.5 MB\/s eta 0:00:01\r     |████████████████████████████████| 108 kB 38.5 MB\/s            \r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow-hub) (1.21.5)\r\n",
      "Requirement already satisfied: protobuf>=3.8.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow-hub) (3.19.4)\r\n",
      "Installing collected packages: tensorflow-hub\r\n",
      "Successfully installed tensorflow-hub-0.12.0\r\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\r\n",
      "You should consider upgrading via the '\/opt\/python\/envs\/default\/bin\/python -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"KfWF9iK5Ta4KXR1LE7ejBv"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "pip install tensorflow-text"
   ],
   "execution_count":117,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (3.6.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (3.3.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.20 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.21.5)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (0.2.0)\r\n",
      "Collecting keras<2.9,>=2.8.0rc0\r\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\r\n",
      "\u001b[?25l\r\r     |▎                               | 10 kB 35.3 MB\/s eta 0:00:01\r     |▌                               | 20 kB 42.9 MB\/s eta 0:00:01\r     |▊                               | 30 kB 51.2 MB\/s eta 0:00:01\r     |█                               | 40 kB 55.5 MB\/s eta 0:00:01\r     |█▏                              | 51 kB 58.1 MB\/s eta 0:00:01\r     |█▍                              | 61 kB 61.7 MB\/s eta 0:00:01\r     |█▋                              | 71 kB 63.1 MB\/s eta 0:00:01\r     |██                              | 81 kB 64.1 MB\/s eta 0:00:01\r     |██▏                             | 92 kB 66.2 MB\/s eta 0:00:01\r     |██▍                             | 102 kB 67.3 MB\/s eta 0:00:01\r     |██▋                             | 112 kB 67.3 MB\/s eta 0:00:01\r     |██▉                             | 122 kB 67.3 MB\/s eta 0:00:01\r     |███                             | 133 kB 67.3 MB\/s eta 0:00:01\r     |███▎                            | 143 kB 67.3 MB\/s eta 0:00:01\r     |███▋                            | 153 kB 67.3 MB\/s eta 0:00:01\r     |███▉                            | 163 kB 67.3 MB\/s eta 0:00:01\r     |████                            | 174 kB 67.3 MB\/s eta 0:00:01\r     |████▎                           | 184 kB 67.3 MB\/s eta 0:00:01\r     |████▌                           | 194 kB 67.3 MB\/s eta 0:00:01\r     |████▊                           | 204 kB 67.3 MB\/s eta 0:00:01\r     |█████                           | 215 kB 67.3 MB\/s eta 0:00:01\r     |█████▎                          | 225 kB 67.3 MB\/s eta 0:00:01\r     |█████▌                          | 235 kB 67.3 MB\/s eta 0:00:01\r     |█████▊                          | 245 kB 67.3 MB\/s eta 0:00:01\r     |██████                          | 256 kB 67.3 MB\/s eta 0:00:01\r     |██████▏                         | 266 kB 67.3 MB\/s eta 0:00:01\r     |██████▍                         | 276 kB 67.3 MB\/s eta 0:00:01\r     |██████▋                         | 286 kB 67.3 MB\/s eta 0:00:01\r     |███████                         | 296 kB 67.3 MB\/s eta 0:00:01\r     |███████▏                        | 307 kB 67.3 MB\/s eta 0:00:01\r     |███████▍                        | 317 kB 67.3 MB\/s eta 0:00:01\r     |███████▋                        | 327 kB 67.3 MB\/s eta 0:00:01\r     |███████▉                        | 337 kB 67.3 MB\/s eta 0:00:01\r     |████████                        | 348 kB 67.3 MB\/s eta 0:00:01\r     |████████▎                       | 358 kB 67.3 MB\/s eta 0:00:01\r     |████████▋                       | 368 kB 67.3 MB\/s eta 0:00:01\r     |████████▉                       | 378 kB 67.3 MB\/s eta 0:00:01\r     |█████████                       | 389 kB 67.3 MB\/s eta 0:00:01\r     |█████████▎                      | 399 kB 67.3 MB\/s eta 0:00:01\r     |█████████▌                      | 409 kB 67.3 MB\/s eta 0:00:01\r     |█████████▊                      | 419 kB 67.3 MB\/s eta 0:00:01\r     |██████████                      | 430 kB 67.3 MB\/s eta 0:00:01\r     |██████████▏                     | 440 kB 67.3 MB\/s eta 0:00:01\r     |██████████▌                     | 450 kB 67.3 MB\/s eta 0:00:01\r     |██████████▊                     | 460 kB 67.3 MB\/s eta 0:00:01\r     |███████████                     | 471 kB 67.3 MB\/s eta 0:00:01\r     |███████████▏                    | 481 kB 67.3 MB\/s eta 0:00:01\r     |███████████▍                    | 491 kB 67.3 MB\/s eta 0:00:01\r     |███████████▋                    | 501 kB 67.3 MB\/s eta 0:00:01\r     |███████████▉                    | 512 kB 67.3 MB\/s eta 0:00:01\r     |████████████▏                   | 522 kB 67.3 MB\/s eta 0:00:01\r     |████████████▍                   | 532 kB 67.3 MB\/s eta 0:00:01\r     |████████████▋                   | 542 kB 67.3 MB\/s eta 0:00:01\r     |████████████▉                   | 552 kB 67.3 MB\/s eta 0:00:01\r     |█████████████                   | 563 kB 67.3 MB\/s eta 0:00:01\r     |█████████████▎                  | 573 kB 67.3 MB\/s eta 0:00:01\r     |█████████████▌                  | 583 kB 67.3 MB\/s eta 0:00:01\r     |█████████████▉                  | 593 kB 67.3 MB\/s eta 0:00:01\r     |██████████████                  | 604 kB 67.3 MB\/s eta 0:00:01\r     |██████████████▎                 | 614 kB 67.3 MB\/s eta 0:00:01\r     |██████████████▌                 | 624 kB 67.3 MB\/s eta 0:00:01\r     |██████████████▊                 | 634 kB 67.3 MB\/s eta 0:00:01\r     |███████████████                 | 645 kB 67.3 MB\/s eta 0:00:01\r     |███████████████▏                | 655 kB 67.3 MB\/s eta 0:00:01\r     |███████████████▌                | 665 kB 67.3 MB\/s eta 0:00:01\r     |███████████████▊                | 675 kB 67.3 MB\/s eta 0:00:01\r     |████████████████                | 686 kB 67.3 MB\/s eta 0:00:01\r     |████████████████▏               | 696 kB 67.3 MB\/s eta 0:00:01\r     |████████████████▍               | 706 kB 67.3 MB\/s eta 0:00:01\r     |████████████████▋               | 716 kB 67.3 MB\/s eta 0:00:01\r     |████████████████▉               | 727 kB 67.3 MB\/s eta 0:00:01\r     |█████████████████▏              | 737 kB 67.3 MB\/s eta 0:00:01\r     |█████████████████▍              | 747 kB 67.3 MB\/s eta 0:00:01\r     |█████████████████▋              | 757 kB 67.3 MB\/s eta 0:00:01\r     |█████████████████▉              | 768 kB 67.3 MB\/s eta 0:00:01\r     |██████████████████              | 778 kB 67.3 MB\/s eta 0:00:01\r     |██████████████████▎             | 788 kB 67.3 MB\/s eta 0:00:01\r     |██████████████████▌             | 798 kB 67.3 MB\/s eta 0:00:01\r     |██████████████████▉             | 808 kB 67.3 MB\/s eta 0:00:01\r     |███████████████████             | 819 kB 67.3 MB\/s eta 0:00:01\r     |███████████████████▎            | 829 kB 67.3 MB\/s eta 0:00:01\r     |███████████████████▌            | 839 kB 67.3 MB\/s eta 0:00:01\r     |███████████████████▊            | 849 kB 67.3 MB\/s eta 0:00:01\r     |████████████████████            | 860 kB 67.3 MB\/s eta 0:00:01\r     |████████████████████▏           | 870 kB 67.3 MB\/s eta 0:00:01\r     |████████████████████▍           | 880 kB 67.3 MB\/s eta 0:00:01\r     |████████████████████▊           | 890 kB 67.3 MB\/s eta 0:00:01\r     |█████████████████████           | 901 kB 67.3 MB\/s eta 0:00:01\r     |█████████████████████▏          | 911 kB 67.3 MB\/s eta 0:00:01\r     |█████████████████████▍          | 921 kB 67.3 MB\/s eta 0:00:01\r     |█████████████████████▋          | 931 kB 67.3 MB\/s eta 0:00:01\r     |█████████████████████▉          | 942 kB 67.3 MB\/s eta 0:00:01\r     |██████████████████████          | 952 kB 67.3 MB\/s eta 0:00:01\r     |██████████████████████▍         | 962 kB 67.3 MB\/s eta 0:00:01\r     |██████████████████████▋         | 972 kB 67.3 MB\/s eta 0:00:01\r     |██████████████████████▉         | 983 kB 67.3 MB\/s eta 0:00:01\r     |███████████████████████         | 993 kB 67.3 MB\/s eta 0:00:01\r     |███████████████████████▎        | 1.0 MB 67.3 MB\/s eta 0:00:01\r     |███████████████████████▌        | 1.0 MB 67.3 MB\/s eta 0:00:01\r     |███████████████████████▊        | 1.0 MB 67.3 MB\/s eta 0:00:01\r     |████████████████████████        | 1.0 MB 67.3 MB\/s eta 0:00:01\r     |████████████████████████▎       | 1.0 MB 67.3 MB\/s eta 0:00:01\r     |████████████████████████▌       | 1.1 MB 67.3 MB\/s eta 0:00:01\r     |████████████████████████▊       | 1.1 MB 67.3 MB\/s eta 0:00:01\r     |█████████████████████████       | 1.1 MB 67.3 MB\/s eta 0:00:01\r     |█████████████████████████▏      | 1.1 MB 67.3 MB\/s eta 0:00:01\r     |█████████████████████████▍      | 1.1 MB 67.3 MB\/s eta 0:00:01\r     |█████████████████████████▊      | 1.1 MB 67.3 MB\/s eta 0:00:01\r     |██████████████████████████      | 1.1 MB 67.3 MB\/s eta 0:00:01\r     |██████████████████████████▏     | 1.1 MB 67.3 MB\/s eta 0:00:01\r     |██████████████████████████▍     | 1.1 MB 67.3 MB\/s eta 0:00:01\r     |██████████████████████████▋     | 1.1 MB 67.3 MB\/s eta 0:00:01\r     |██████████████████████████▉     | 1.2 MB 67.3 MB\/s eta 0:00:01\r     |███████████████████████████     | 1.2 MB 67.3 MB\/s eta 0:00:01\r     |███████████████████████████▍    | 1.2 MB 67.3 MB\/s eta 0:00:01\r     |███████████████████████████▋    | 1.2 MB 67.3 MB\/s eta 0:00:01\r     |███████████████████████████▉    | 1.2 MB 67.3 MB\/s eta 0:00:01\r     |████████████████████████████    | 1.2 MB 67.3 MB\/s eta 0:00:01\r     |████████████████████████████▎   | 1.2 MB 67.3 MB\/s eta 0:00:01\r     |████████████████████████████▌   | 1.2 MB 67.3 MB\/s eta 0:00:01\r     |████████████████████████████▊   | 1.2 MB 67.3 MB\/s eta 0:00:01\r     |█████████████████████████████   | 1.2 MB 67.3 MB\/s eta 0:00:01\r     |█████████████████████████████▎  | 1.3 MB 67.3 MB\/s eta 0:00:01\r     |█████████████████████████████▌  | 1.3 MB 67.3 MB\/s eta 0:00:01\r     |█████████████████████████████▊  | 1.3 MB 67.3 MB\/s eta 0:00:01\r     |██████████████████████████████  | 1.3 MB 67.3 MB\/s eta 0:00:01\r     |██████████████████████████████▏ | 1.3 MB 67.3 MB\/s eta 0:00:01\r     |██████████████████████████████▍ | 1.3 MB 67.3 MB\/s eta 0:00:01\r     |██████████████████████████████▋ | 1.3 MB 67.3 MB\/s eta 0:00:01\r     |███████████████████████████████ | 1.3 MB 67.3 MB\/s eta 0:00:01\r     |███████████████████████████████▏| 1.3 MB 67.3 MB\/s eta 0:00:01\r     |███████████████████████████████▍| 1.4 MB 67.3 MB\/s eta 0:00:01\r     |███████████████████████████████▋| 1.4 MB 67.3 MB\/s eta 0:00:01\r     |███████████████████████████████▉| 1.4 MB 67.3 MB\/s eta 0:00:01\r     |████████████████████████████████| 1.4 MB 67.3 MB\/s            \r\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (3.19.4)\r\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\r\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\r\n",
      "\u001b[?25l\r\r     |▊                               | 10 kB 35.1 MB\/s eta 0:00:01\r     |█▍                              | 20 kB 42.9 MB\/s eta 0:00:01\r     |██▏                             | 30 kB 50.7 MB\/s eta 0:00:01\r     |██▉                             | 40 kB 54.9 MB\/s eta 0:00:01\r     |███▌                            | 51 kB 57.4 MB\/s eta 0:00:01\r     |████▎                           | 61 kB 61.1 MB\/s eta 0:00:01\r     |█████                           | 71 kB 62.1 MB\/s eta 0:00:01\r     |█████▊                          | 81 kB 63.2 MB\/s eta 0:00:01\r     |██████▍                         | 92 kB 65.4 MB\/s eta 0:00:01\r     |███████                         | 102 kB 66.1 MB\/s eta 0:00:01\r     |███████▉                        | 112 kB 66.1 MB\/s eta 0:00:01\r     |████████▌                       | 122 kB 66.1 MB\/s eta 0:00:01\r     |█████████▏                      | 133 kB 66.1 MB\/s eta 0:00:01\r     |██████████                      | 143 kB 66.1 MB\/s eta 0:00:01\r     |██████████▋                     | 153 kB 66.1 MB\/s eta 0:00:01\r     |███████████▍                    | 163 kB 66.1 MB\/s eta 0:00:01\r     |████████████                    | 174 kB 66.1 MB\/s eta 0:00:01\r     |████████████▊                   | 184 kB 66.1 MB\/s eta 0:00:01\r     |█████████████▌                  | 194 kB 66.1 MB\/s eta 0:00:01\r     |██████████████▏                 | 204 kB 66.1 MB\/s eta 0:00:01\r     |██████████████▉                 | 215 kB 66.1 MB\/s eta 0:00:01\r     |███████████████▋                | 225 kB 66.1 MB\/s eta 0:00:01\r     |████████████████▎               | 235 kB 66.1 MB\/s eta 0:00:01\r     |█████████████████               | 245 kB 66.1 MB\/s eta 0:00:01\r     |█████████████████▊              | 256 kB 66.1 MB\/s eta 0:00:01\r     |██████████████████▍             | 266 kB 66.1 MB\/s eta 0:00:01\r     |███████████████████▏            | 276 kB 66.1 MB\/s eta 0:00:01\r     |███████████████████▉            | 286 kB 66.1 MB\/s eta 0:00:01\r     |████████████████████▌           | 296 kB 66.1 MB\/s eta 0:00:01\r     |█████████████████████▎          | 307 kB 66.1 MB\/s eta 0:00:01\r     |██████████████████████          | 317 kB 66.1 MB\/s eta 0:00:01\r     |██████████████████████▊         | 327 kB 66.1 MB\/s eta 0:00:01\r     |███████████████████████▍        | 337 kB 66.1 MB\/s eta 0:00:01\r     |████████████████████████        | 348 kB 66.1 MB\/s eta 0:00:01\r     |████████████████████████▉       | 358 kB 66.1 MB\/s eta 0:00:01\r     |█████████████████████████▌      | 368 kB 66.1 MB\/s eta 0:00:01\r     |██████████████████████████▏     | 378 kB 66.1 MB\/s eta 0:00:01\r     |███████████████████████████     | 389 kB 66.1 MB\/s eta 0:00:01\r     |███████████████████████████▋    | 399 kB 66.1 MB\/s eta 0:00:01\r     |████████████████████████████▍   | 409 kB 66.1 MB\/s eta 0:00:01\r     |█████████████████████████████   | 419 kB 66.1 MB\/s eta 0:00:01\r     |█████████████████████████████▊  | 430 kB 66.1 MB\/s eta 0:00:01\r     |██████████████████████████████▌ | 440 kB 66.1 MB\/s eta 0:00:01\r     |███████████████████████████████▏| 450 kB 66.1 MB\/s eta 0:00:01\r     |███████████████████████████████▉| 460 kB 66.1 MB\/s eta 0:00:01\r     |████████████████████████████████| 462 kB 66.1 MB\/s            \r\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.44.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.13.3)\r\n",
      "Requirement already satisfied: absl-py>=0.4.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.0.0)\r\n",
      "Requirement already satisfied: setuptools in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (56.0.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.16.0)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (0.24.0)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.1.2)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.6.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (4.1.1)\r\n",
      "Requirement already satisfied: gast>=0.2.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (0.4.0)\r\n",
      "Requirement already satisfied: flatbuffers>=1.12 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (2.0)\r\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (2.8.0)\r\n",
      "Requirement already satisfied: libclang>=9.0.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (13.0.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.37.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.4.6)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2.26.0)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.8.1)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.6.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.3.6)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2.6.0)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2.0.3)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (4.8)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.2.8)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (5.0.0)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.3.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (4.11.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.26.8)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2021.10.8)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2.0.12)\r\n",
      "Requirement already satisfied: zipp>=0.5 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.7.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.2.0)\r\n",
      "Installing collected packages: tf-estimator-nightly, keras, tensorflow, tensorflow-text\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 2.7.0\r\n",
      "    Uninstalling keras-2.7.0:\r\n",
      "      Successfully uninstalled keras-2.7.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-cpu 2.7.0 requires keras<2.8,>=2.7.0rc0, but you have keras 2.8.0 which is incompatible.\u001b[0m\r\n",
      "Successfully installed keras-2.8.0 tensorflow-2.8.0 tensorflow-text-2.8.1 tf-estimator-nightly-2.8.0.dev2021122109\r\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\r\n",
      "You should consider upgrading via the '\/opt\/python\/envs\/default\/bin\/python -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"xUcK3lJs2KK6KuX8rbDSMb"
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text  # Imports TF ops for preprocessing.\n",
    "\n",
    "# Define some sentences to feed into the model\n",
    "sentences = [\n",
    "  \"Here We Go Then, You And I is a 1999 album by Norwegian pop artist Morten Abel. It was Abel's second CD as a solo artist.\",\n",
    "  \"The album went straight to number one on the Norwegian album chart, and sold to double platinum.\",\n",
    "  \"Ceylon spinach is a common name for several plants and may refer to: Basella alba Talinum fruticosum\",\n",
    "  \"A solar eclipse occurs when the Moon passes between Earth and the Sun, thereby totally or partly obscuring the image of the Sun for a viewer on Earth.\",\n",
    "  \"A partial solar eclipse occurs in the polar regions of the Earth when the center of the Moon's shadow misses the Earth.\",\n",
    "]\n",
    "\n",
    "# Load the BERT encoder and preprocessing models\n",
    "preprocess = hub.load('https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_preprocess\/3')\n",
    "bert = hub.load('https:\/\/tfhub.dev\/google\/experts\/bert\/wiki_books\/sst2\/2')\n",
    "\n",
    "# Convert the sentences to bert inputs\n",
    "bert_inputs = preprocess(sentences)\n",
    "\n",
    "# Feed the inputs to the model to get the pooled and sequence outputs\n",
    "bert_outputs = bert(bert_inputs, training=False)\n",
    "pooled_output = bert_outputs['pooled_output']\n",
    "sequence_output = bert_outputs['sequence_output']\n",
    "\n",
    "print('\\nSentences:')\n",
    "print(sentences)\n",
    "print('\\nPooled output:')\n",
    "print(pooled_output)\n",
    "print('\\nSequence output:')\n",
    "print(sequence_output)"
   ],
   "execution_count":119,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "\n",
      "Sentences:\n",
      "[\"Here We Go Then, You And I is a 1999 album by Norwegian pop artist Morten Abel. It was Abel's second CD as a solo artist.\", 'The album went straight to number one on the Norwegian album chart, and sold to double platinum.', 'Ceylon spinach is a common name for several plants and may refer to: Basella alba Talinum fruticosum', 'A solar eclipse occurs when the Moon passes between Earth and the Sun, thereby totally or partly obscuring the image of the Sun for a viewer on Earth.', \"A partial solar eclipse occurs in the polar regions of the Earth when the center of the Moon's shadow misses the Earth.\"]\n",
      "\n",
      "Pooled output:\n",
      "tf.Tensor(\n",
      "[[ 0.45328465  0.40238342  0.68191683 ...  0.8772831   0.8688862\n",
      "  -0.47354415]\n",
      " [-0.5207477  -0.08203764  0.71232826 ...  0.5803519   0.89730525\n",
      "  -0.7298698 ]\n",
      " [ 0.5718872   0.16353984 -0.6850582  ...  0.5572136  -0.8921097\n",
      "  -0.7106601 ]\n",
      " [ 0.91455305  0.3213804  -0.62168694 ... -0.4874627   0.41295788\n",
      "   0.77592385]\n",
      " [ 0.9174914   0.06678771 -0.437904   ... -0.21163465  0.11979885\n",
      "   0.70106184]], shape=(5, 768), dtype=float32)\n",
      "\n",
      "Sequence output:\n",
      "tf.Tensor(\n",
      "[[[ 4.88826632e-01  4.26489532e-01  8.32688332e-01 ...  1.36385059e+00\n",
      "    1.32851601e+00 -5.14629185e-01]\n",
      "  [ 9.38493311e-01  2.91558504e-01  6.45747423e-01 ...  1.31544006e+00\n",
      "   -4.87500757e-01  4.95140880e-01]\n",
      "  [ 4.75247383e-01  2.98874766e-01  6.08293712e-01 ...  4.35344338e-01\n",
      "    6.88173532e-01 -2.56192207e-01]\n",
      "  ...\n",
      "  [-4.89344418e-01  8.68353993e-02  6.41013682e-01 ...  6.26745641e-01\n",
      "    4.77468014e-01 -5.65383613e-01]\n",
      "  [-3.71468097e-01  1.69177026e-01  7.12941647e-01 ...  6.27167642e-01\n",
      "    3.14989030e-01 -6.28091872e-01]\n",
      "  [-4.86974537e-01  1.02857836e-01  8.91172051e-01 ...  4.30188656e-01\n",
      "    3.77779424e-01 -7.26033211e-01]]\n",
      "\n",
      " [[-5.77365041e-01 -8.22224468e-02  8.91894579e-01 ...  6.62993073e-01\n",
      "    1.45821452e+00 -9.28448677e-01]\n",
      "  [-8.40859830e-01 -1.05622754e-01  8.77411962e-01 ...  6.38006926e-01\n",
      "    1.43251669e+00 -5.12069285e-01]\n",
      "  [-4.63975251e-01 -4.20738816e-01  6.44164562e-01 ...  8.14404726e-01\n",
      "    1.29922593e+00 -5.98816216e-01]\n",
      "  ...\n",
      "  [-9.64915991e-01 -2.28245556e-01  1.02885413e+00 ...  1.32961214e-01\n",
      "    1.11951208e+00 -1.00562072e+00]\n",
      "  [-8.58284056e-01 -2.68650770e-01  1.18677163e+00 ...  4.13587630e-01\n",
      "    1.15259314e+00 -1.13035667e+00]\n",
      "  [-8.81638825e-01 -3.02886724e-01  1.22516274e+00 ...  2.92158961e-01\n",
      "    1.20386553e+00 -9.09297884e-01]]\n",
      "\n",
      " [[ 6.50322795e-01  1.65021688e-01 -8.38583708e-01 ...  6.28782868e-01\n",
      "   -1.43216634e+00 -8.88516247e-01]\n",
      "  [ 8.03727135e-02  4.84194547e-01 -1.13542855e+00 ...  2.76425891e-02\n",
      "   -1.27342772e+00 -6.53176308e-01]\n",
      "  [-4.16071087e-01  3.36833775e-01 -1.00182188e+00 ... -5.87869436e-04\n",
      "   -1.35352063e+00 -1.18691695e+00]\n",
      "  ...\n",
      "  [ 5.07928371e-01  7.38599300e-01 -8.35333467e-01 ...  6.45096749e-02\n",
      "   -1.88611209e+00 -9.91281807e-01]\n",
      "  [ 5.51044345e-01  7.28136420e-01 -8.20376098e-01 ...  4.37296219e-02\n",
      "   -1.91507053e+00 -1.03133619e+00]\n",
      "  [ 5.58018923e-01  7.51645505e-01 -9.53126550e-01 ...  7.74316043e-02\n",
      "   -1.98882341e+00 -1.07003260e+00]]\n",
      "\n",
      " [[ 1.55467188e+00  3.33185792e-01 -7.27750063e-01 ... -5.32726824e-01\n",
      "    4.39171970e-01  1.03504503e+00]\n",
      "  [ 1.26357567e+00  8.24849188e-01 -1.10092402e+00 ... -4.94461238e-01\n",
      "   -2.97126174e-02  4.73278761e-01]\n",
      "  [ 1.34107971e+00  6.20311737e-01 -1.37525511e+00 ... -8.47145975e-01\n",
      "   -3.47364873e-01  5.57110310e-01]\n",
      "  ...\n",
      "  [ 1.81083941e+00  1.15520978e+00 -6.27862096e-01 ...  1.32490814e-01\n",
      "    1.65559143e-01  7.54892886e-01]\n",
      "  [ 1.79005373e+00  1.27339232e+00 -8.06309283e-01 ...  2.10280031e-01\n",
      "    1.42742217e-01  7.04276621e-01]\n",
      "  [ 1.77186763e+00  1.42296422e+00 -6.15323544e-01 ...  1.79775238e-01\n",
      "   -1.48998156e-01  5.92045665e-01]]\n",
      "\n",
      " [[ 1.57293522e+00  6.68872893e-02 -4.69634533e-01 ... -2.14882046e-01\n",
      "    1.20376945e-01  8.69385540e-01]\n",
      "  [ 1.33567452e+00  7.06928611e-01 -8.86397004e-01 ... -9.01170447e-02\n",
      "   -1.77512139e-01  4.43907470e-01]\n",
      "  [ 1.13371325e+00  4.57025677e-01 -7.65147686e-01 ... -8.81720334e-02\n",
      "   -6.92269802e-01  1.57160386e-01]\n",
      "  ...\n",
      "  [ 1.73448014e+00  1.08369875e+00 -5.11250138e-01 ...  3.23260903e-01\n",
      "   -5.26115954e-01  4.58343297e-01]\n",
      "  [ 1.69163620e+00  1.06362808e+00 -5.90602577e-01 ...  4.15278524e-01\n",
      "   -3.46137404e-01  4.67999876e-01]\n",
      "  [ 1.61735106e+00  1.16539097e+00 -5.00584364e-01 ...  3.06122631e-01\n",
      "   -4.07356858e-01  3.99886459e-01]]], shape=(5, 128, 768), dtype=float32)\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false,
     "node_id":"L12C7Sg07IcBSdFb2QldR5"
    }
   }
  }
 ],
 "metadata":{
  "datalore":{
   "version":1,
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    {
     "name":"nltk",
     "version":"3.7",
     "source":"PIP"
    }
   ]
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}